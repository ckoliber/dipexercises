{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPuBOW0K6lig"
      },
      "source": [
        "# DIP Answers\n",
        "\n",
        "- **Answer Set**: Final Project\n",
        "- **Full Name**: Mohammad Hosein Nemati\n",
        "- **Student Code**: `610300185`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6595aa20"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPbGq7fh6liq"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this problem, we are going to change some parameters in order to optimize the accuracy of [**Nested Hierarchical Transformer**](https://github.com/google-research/nested-transformer) model for **CIFAR10** dataset.  \n",
        "Then we will compare the reported metrics to previously trained models in `article`\n",
        "\n",
        "In the first step, we will install required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-CQR0q1m6liq",
        "outputId": "454c3d63-9014-4c89-91d0-90916bb2fa1a",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting clu==0.0.3\n",
            "  Downloading clu-0.0.3-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from clu==0.0.3) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from clu==0.0.3) (1.2.0)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from clu==0.0.3) (0.3.14+cuda11.cudnn805)\n",
            "Collecting flax\n",
            "  Downloading flax-0.5.3-py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 19.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from clu==0.0.3) (0.3.14)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from clu==0.0.3) (1.21.6)\n",
            "Collecting ml-collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from clu==0.0.3) (4.6.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax->clu==0.0.3) (1.0.4)\n",
            "Collecting tensorstore\n",
            "  Downloading tensorstore-0.1.22-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 53.3 MB/s \n",
            "\u001b[?25hCollecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 56.0 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.4.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax->clu==0.0.3) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from flax->clu==0.0.3) (4.1.1)\n",
            "Collecting rich~=11.1\n",
            "  Downloading rich-11.2.0-py3-none-any.whl (217 kB)\n",
            "\u001b[K     |████████████████████████████████| 217 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax->clu==0.0.3) (0.6.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax->clu==0.0.3) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax->clu==0.0.3) (1.7.3)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich~=11.1->flax->clu==0.0.3) (2.6.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax->clu==0.0.3) (3.8.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax->clu==0.0.3) (5.9.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib->clu==0.0.3) (2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu==0.0.3) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu==0.0.3) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu==0.0.3) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax->clu==0.0.3) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->flax->clu==0.0.3) (1.15.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml-collections->clu==0.0.3) (0.5.5)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.4-py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax->clu==0.0.3) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax->clu==0.0.3) (0.1.7)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (0.26.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (1.47.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (0.5.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->clu==0.0.3) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->clu==0.0.3) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->clu==0.0.3) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (4.12.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->clu==0.0.3) (3.2.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu==0.0.3) (0.3.5.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu==0.0.3) (2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu==0.0.3) (4.64.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu==0.0.3) (1.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->clu==0.0.3) (0.10.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->clu==0.0.3) (1.56.4)\n",
            "Building wheels for collected packages: ml-collections\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94524 sha256=bf8dbd03d8e23893c81d5539bbadb3d60cedfef36a798703d23ac550da696839\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/da/64/33c926a1b10ff19791081b705879561b715a8341a856a3bbd2\n",
            "Successfully built ml-collections\n",
            "Installing collected packages: commonmark, colorama, chex, tensorstore, rich, PyYAML, optax, ml-collections, flax, clu\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 chex-0.1.4 clu-0.0.3 colorama-0.4.5 commonmark-0.9.1 flax-0.5.3 ml-collections-0.1.1 optax-0.1.3 rich-11.2.0 tensorstore-0.1.22\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flax==0.3.4\n",
            "  Downloading flax-0.3.4-py3-none-any.whl (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax==0.3.4) (1.0.4)\n",
            "Requirement already satisfied: jax>=0.2.13 in /usr/local/lib/python3.7/dist-packages (from flax==0.3.4) (0.3.14)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax==0.3.4) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax==0.3.4) (3.2.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (from flax==0.3.4) (0.1.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.13->flax==0.3.4) (4.1.1)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.13->flax==0.3.4) (0.6.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.13->flax==0.3.4) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.13->flax==0.3.4) (1.7.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.13->flax==0.3.4) (1.2.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.2.13->flax==0.3.4) (5.9.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.2.13->flax==0.3.4) (3.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax==0.3.4) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax==0.3.4) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax==0.3.4) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax==0.3.4) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->flax==0.3.4) (1.15.0)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax->flax==0.3.4) (0.3.14+cuda11.cudnn805)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax->flax==0.3.4) (0.1.4)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax==0.3.4) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax==0.3.4) (0.1.7)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax->flax==0.3.4) (2.0)\n",
            "Installing collected packages: flax\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.5.3\n",
            "    Uninstalling flax-0.5.3:\n",
            "      Successfully uninstalled flax-0.5.3\n",
            "Successfully installed flax-0.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jax==0.2.14\n",
            "  Downloading jax-0.2.14.tar.gz (669 kB)\n",
            "\u001b[K     |████████████████████████████████| 669 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from jax==0.2.14) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax==0.2.14) (1.2.0)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from jax==0.2.14) (3.3.0)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.2.14-py3-none-any.whl size=771352 sha256=03ed942e92a2785cc1d34f4f5e63a442e1275cdd3353036ab17f9b62eac6c9b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/bd/25/923906d87d262ee0be5c68b248d1a8249d028603582a256266\n",
            "Successfully built jax\n",
            "Installing collected packages: jax\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.3.14\n",
            "    Uninstalling jax-0.3.14:\n",
            "      Successfully uninstalled jax-0.3.14\n",
            "Successfully installed jax-0.2.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jaxlib==0.1.67\n",
            "  Downloading jaxlib-0.1.67-cp37-none-manylinux2010_x86_64.whl (45.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 45.3 MB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.67) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.67) (1.7.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.67) (2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.1.67) (1.2.0)\n",
            "Installing collected packages: jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.3.14+cuda11.cudnn805\n",
            "    Uninstalling jaxlib-0.3.14+cuda11.cudnn805:\n",
            "      Successfully uninstalled jaxlib-0.3.14+cuda11.cudnn805\n",
            "Successfully installed jaxlib-0.1.67\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ml_collections in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ml_collections) (1.15.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from ml_collections) (0.5.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from ml_collections) (1.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from ml_collections) (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-cpu==2.5.0\n",
            "  Downloading tensorflow_cpu-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (168.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 168.3 MB 43 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.6.3)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 37.2 MB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 53.3 MB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (1.1.2)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 43.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (0.37.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (2.8.0)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 41.9 MB/s \n",
            "\u001b[?25hCollecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 43.5 MB/s \n",
            "\u001b[?25hCollecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-cpu==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow-cpu==2.5.0) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow-cpu==2.5.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow-cpu==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow-cpu==2.5.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow-cpu==2.5.0) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68706 sha256=8ab7ec06ac970d75aba4672ab9cd06800173dce34cfdddedf751e378f76179bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, keras-nightly, gast, flatbuffers, tensorflow-cpu\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.47.0\n",
            "    Uninstalling grpcio-1.47.0:\n",
            "      Successfully uninstalled grpcio-1.47.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.2.0\n",
            "    Uninstalling absl-py-1.2.0:\n",
            "      Successfully uninstalled absl-py-1.2.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.5.0 which is incompatible.\n",
            "optax 0.1.3 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "cmdstanpy 1.0.4 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.4.0 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 tensorflow-cpu-2.5.0 tensorflow-estimator-2.5.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-datasets==4.3.0\n",
            "  Downloading tensorflow_datasets-4.3.0-py3-none-any.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (0.16.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (0.3.5.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (5.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (4.64.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (1.9.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (22.1.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (0.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets==4.3.0) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets==4.3.0) (2022.6.15)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow-datasets==4.3.0) (3.8.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets==4.3.0) (1.56.4)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.6.0\n",
            "    Uninstalling tensorflow-datasets-4.6.0:\n",
            "      Successfully uninstalled tensorflow-datasets-4.6.0\n",
            "Successfully installed tensorflow-datasets-4.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons==0.13.0\n",
            "  Downloading tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679 kB)\n",
            "\u001b[K     |████████████████████████████████| 679 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons==0.13.0) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n",
            "Cloning into 'dipexercises'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 107 (delta 24), reused 53 (delta 14), pack-reused 42\u001b[K\n",
            "Receiving objects: 100% (107/107), 41.00 MiB | 25.35 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install absl-py\n",
        "!pip install clu==0.0.3\n",
        "!pip install flax==0.3.4\n",
        "!pip install jax==0.2.14\n",
        "!pip install jaxlib==0.1.67\n",
        "!pip install ml_collections\n",
        "!pip install tensorflow-cpu==2.5.0\n",
        "!pip install tensorflow-datasets==4.3.0\n",
        "!pip install tensorflow_addons==0.13.0\n",
        "\n",
        "!git clone https://github.com/ckoliber/dipexercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKvqN1xY6liu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEtn5ueW6liu"
      },
      "source": [
        "## Model\n",
        "\n",
        "In this section, we will change some parameters of model in order to optimize the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class NestNet(nn.Module):\n",
        "  \"\"\"Nested Transformer Net.\"\"\"\n",
        "  num_classes: int\n",
        "  config: ml_collections.ConfigDict\n",
        "  train: bool = False\n",
        "  dtype: int = jnp.float32\n",
        "  activation_fn: Any = nn.gelu\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    config = self.config\n",
        "    num_layers_per_block = config.num_layers_per_block\n",
        "    num_blocks = len(num_layers_per_block)\n",
        "    # Here we just assume image/patch size are squared.\n",
        "    assert inputs.shape[1] == inputs.shape[2]\n",
        "    assert inputs.shape[1] % config.init_patch_embed_size == 0\n",
        "    input_size_after_patch = inputs.shape[1] // config.init_patch_embed_size\n",
        "    assert input_size_after_patch % config.patch_size == 0\n",
        "    down_sample_ratio = input_size_after_patch // config.patch_size\n",
        "    # There are 4 child nodes for each node.\n",
        "    assert num_blocks == int(np.log(down_sample_ratio) / np.log(2) + 1)\n",
        "\n",
        "    # If `scale_hidden_dims` is provided, at every block, it increases hidden\n",
        "    # dimension and num_heads by `scale_hidden_dims`. Set `scale_hidden_dims=2`\n",
        "    # overall is a common design, so we do not gives the flexibility to control\n",
        "    # layer-wise `scale_hidden_dims` to simplify the architecture.\n",
        "    scale_hidden_dims = config.get(\"scale_hidden_dims\", None)\n",
        "\n",
        "    norm_fn = attn_utils.get_norm_layer(\n",
        "        self.train, self.dtype, norm_type=config.norm_type)\n",
        "    conv_fn = functools.partial(\n",
        "        nn.Conv, dtype=self.dtype, kernel_init=default_kernel_init)\n",
        "    dense_fn = functools.partial(\n",
        "        nn.Dense, dtype=self.dtype, kernel_init=default_kernel_init)\n",
        "    encoder_dict = dict(\n",
        "        num_heads=config.num_heads,\n",
        "        norm_fn=norm_fn,\n",
        "        mlp_ratio=config.mlp_ratio,\n",
        "        attn_type=config.attn_type,\n",
        "        dense_fn=dense_fn,\n",
        "        activation_fn=self.activation_fn,\n",
        "        qkv_bias=config.qkv_bias,\n",
        "        attn_drop=config.attn_drop,\n",
        "        proj_drop=config.proj_drop,\n",
        "        train=self.train,\n",
        "        dtype=self.dtype)\n",
        "    x = self_attention.PatchEmbedding(\n",
        "        conv_fn=conv_fn,\n",
        "        patch_size=(config.init_patch_embed_size, config.init_patch_embed_size),\n",
        "        embedding_dim=config.embedding_dim)(\n",
        "            inputs)\n",
        "    x = attn_utils.block_images(x, (config.patch_size, config.patch_size))\n",
        "    block_idx = 0\n",
        "    total_block_num = np.sum(num_layers_per_block)\n",
        "    path_drop = np.linspace(0, config.stochastic_depth_drop, total_block_num)\n",
        "    for i in range(num_blocks):\n",
        "      x = self_attention.PositionEmbedding()(x)\n",
        "      if scale_hidden_dims and i != 0:\n",
        "        # Overwrite the original num_heads value in encoder_dict so num_heads\n",
        "        # multipled by scale_hidden_dims continueously.\n",
        "        encoder_dict.update(\n",
        "            {\"num_heads\": encoder_dict[\"num_heads\"] * scale_hidden_dims})\n",
        "      for _ in range(num_layers_per_block[i]):\n",
        "        x = self_attention.EncoderNDBlock(\n",
        "            **encoder_dict, path_drop=path_drop[block_idx])(\n",
        "                x)\n",
        "        block_idx = block_idx + 1\n",
        "      if i < num_blocks - 1:\n",
        "        grid_size = int(math.sqrt(x.shape[1]))\n",
        "        if scale_hidden_dims:\n",
        "          output_dim = x.shape[-1] * scale_hidden_dims\n",
        "        else:\n",
        "          output_dim = None\n",
        "\n",
        "        x = self_attention.ConvPool(\n",
        "            grid_size=(grid_size, grid_size),\n",
        "            patch_size=(config.patch_size, config.patch_size),\n",
        "            conv_fn=conv_fn,\n",
        "            dtype=self.dtype,\n",
        "            output_dim=output_dim)(\n",
        "                x)\n",
        "    assert x.shape[1] == 1\n",
        "    assert x.shape[2] == config.patch_size**2\n",
        "\n",
        "    x = norm_fn()(x)\n",
        "    x_pool = jnp.mean(x, axis=(1, 2))\n",
        "    out = dense_fn(self.num_classes)(x_pool)\n",
        "    return out\n",
        "\n",
        "\n",
        "MODELS = {}\n",
        "\n",
        "\n",
        "def register(f):\n",
        "  MODELS[f.__name__] = f\n",
        "  return f\n",
        "\n",
        "\n",
        "def default_config():\n",
        "  \"\"\"Shared configs for models.\"\"\"\n",
        "  nest = ml_collections.ConfigDict()\n",
        "  nest.norm_type = \"LN\"\n",
        "  nest.attn_type = \"local_multi_head\"\n",
        "  nest.mlp_ratio = 4\n",
        "  nest.qkv_bias = True\n",
        "  nest.attn_drop = 0.0\n",
        "  nest.proj_drop = 0.0\n",
        "  nest.stochastic_depth_drop = 0.1\n",
        "  return nest\n",
        "\n",
        "\n",
        "@register\n",
        "def nest_tiny_s16_32(config):\n",
        "  \"\"\"NesT tiny version with sequence length 16 for 32x32 inputs.\"\"\"\n",
        "  nest = default_config()\n",
        "  # Encode one pixel as a word vector.\n",
        "  nest.init_patch_embed_size = 1\n",
        "  # Default max sequencee length is 4x4=16, so it has 4 layers.\n",
        "  nest.patch_size = 4\n",
        "  nest.num_layers_per_block = [3, 3, 3, 3]\n",
        "  nest.embedding_dim = 192\n",
        "  nest.num_heads = 3\n",
        "  nest.attn_type = \"local_multi_query\"\n",
        "\n",
        "  if config.get(\"nest\"):\n",
        "    nest.update(config.nest)\n",
        "  return functools.partial(NestNet, config=nest)\n",
        "\n",
        "\n",
        "@register\n",
        "def nest_small_s16_32(config):\n",
        "  \"\"\"NesT small version with sequence length 16 for 32x32 inputs.\"\"\"\n",
        "  nest = default_config()\n",
        "  nest.init_patch_embed_size = 1\n",
        "  nest.patch_size = 4\n",
        "  nest.num_layers_per_block = [3, 3, 3, 3]\n",
        "  nest.embedding_dim = 384\n",
        "  nest.num_heads = 6\n",
        "  nest.attn_type = \"local_multi_query\"\n",
        "\n",
        "  if config.get(\"nest\"):\n",
        "    nest.update(config.nest)\n",
        "  return functools.partial(NestNet, config=nest)\n",
        "\n",
        "\n",
        "@register\n",
        "def nest_base_s16_32(config):\n",
        "  \"\"\"NesT base version with sequence length 16 for 32x32 inputs.\"\"\"\n",
        "  nest = default_config()\n",
        "  nest.init_patch_embed_size = 1\n",
        "  nest.patch_size = 4\n",
        "  nest.num_layers_per_block = [3, 3, 3, 3]\n",
        "  nest.embedding_dim = 768\n",
        "  nest.num_heads = 12\n",
        "  nest.attn_type = \"local_multi_query\"\n",
        "\n",
        "  if config.get(\"nest\"):\n",
        "    nest.update(config.nest)\n",
        "  return functools.partial(NestNet, config=nest)\n",
        "\n",
        "\n",
        "@register\n",
        "def nest_tiny_s196_224(config):\n",
        "  \"\"\"NesT tiny version with sequence length 49 for 224x224 inputs.\"\"\"\n",
        "  nest = default_config()\n",
        "  # Encode 4x4 pixel as a word vector.\n",
        "  nest.init_patch_embed_size = 4\n",
        "  # Default max sequencee length is 14x14=196, so it has 3 layers:\n",
        "  # Spatial image size: [56, 28, 14]\n",
        "  nest.patch_size = 14\n",
        "  nest.num_layers_per_block = [2, 2, 8]\n",
        "  nest.embedding_dim = 96\n",
        "  nest.num_heads = 3\n",
        "  nest.scale_hidden_dims = 2\n",
        "  nest.stochastic_depth_drop = 0.2\n",
        "  nest.attn_type = \"local_multi_head\"\n",
        "\n",
        "  if config.get(\"nest\"):\n",
        "    nest.update(config.nest)\n",
        "  return functools.partial(NestNet, config=nest)\n",
        "\n",
        "\n",
        "@register\n",
        "def nest_small_s196_224(config):\n",
        "  \"\"\"NesT small version with sequence length 196 for 224x224 inputs.\"\"\"\n",
        "  nest = default_config()\n",
        "  nest.init_patch_embed_size = 4\n",
        "  nest.patch_size = 14\n",
        "  nest.num_layers_per_block = [2, 2, 20]\n",
        "  nest.embedding_dim = 96\n",
        "  nest.num_heads = 3\n",
        "  nest.scale_hidden_dims = 2\n",
        "  nest.stochastic_depth_drop = 0.3\n",
        "  nest.attn_type = \"local_multi_head\"\n",
        "\n",
        "  if config.get(\"nest\"):\n",
        "    nest.update(config.nest)\n",
        "  return functools.partial(NestNet, config=nest)\n",
        "\n",
        "\n",
        "@register\n",
        "def nest_base_s196_224(config):\n",
        "  \"\"\"NesT base version with sequence length 196 for 224x224 inputs.\"\"\"\n",
        "  nest = default_config()\n",
        "  nest.init_patch_embed_size = 4\n",
        "  nest.patch_size = 14\n",
        "  nest.num_layers_per_block = [2, 2, 20]\n",
        "  nest.embedding_dim = 128\n",
        "  nest.num_heads = 4\n",
        "  nest.scale_hidden_dims = 2\n",
        "  nest.stochastic_depth_drop = 0.5\n",
        "  nest.attn_type = \"local_multi_head\"\n",
        "\n",
        "  if config.get(\"nest\"):\n",
        "    nest.update(config.nest)\n",
        "  return functools.partial(NestNet, config=nest)\n",
        "\n",
        "\n",
        "def create_model(name, config):\n",
        "  \"\"\"Creates model partial function.\"\"\"\n",
        "  if name not in MODELS:\n",
        "    raise ValueError(f\"Model {name} does not exist.\")\n",
        "  return MODELS[name](config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvfx1VyA6liz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6dJimIr6li0"
      },
      "source": [
        "## Training\n",
        "\n",
        "Run the command bellow in order to train the `NesT` model and report evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFaH-spA6li1",
        "outputId": "ebda1e01-d6cb-45f8-8a88-d69942f3153f",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I0808 19:27:07.338225 139645475628928 main.py:49] Using JAX backend target local\n",
            "I0808 19:27:07.338693 139645475628928 main.py:52] Using JAX XLA backend \n",
            "I0808 19:27:07.341539 139645475628928 tpu_client.py:54] Starting the local TPU driver.\n",
            "I0808 19:27:07.341964 139645475628928 xla_bridge.py:212] Unable to initialize backend 'tpu_driver': Not found: Unable to find driver in registry given worker: local://\n",
            "I0808 19:27:07.342265 139645475628928 xla_bridge.py:212] Unable to initialize backend 'gpu': Not found: Could not find registered platform with name: \"cuda\". Available platform names are: Interpreter Host\n",
            "I0808 19:27:07.342418 139645475628928 xla_bridge.py:212] Unable to initialize backend 'tpu': Invalid argument: TpuPlatform is not available.\n",
            "W0808 19:27:07.342489 139645475628928 xla_bridge.py:215] No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
            "I0808 19:27:07.342578 139645475628928 main.py:54] JAX host: 0 / 1\n",
            "I0808 19:27:07.342785 139645475628928 main.py:55] JAX devices: [CpuDevice(id=0)]\n",
            "2022-08-08 19:27:07.833057: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Not found: Error executing an HTTP request: HTTP response code 404\".\n",
            "I0808 19:27:08.068861 139645475628928 dataset_info.py:453] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: cifar10/3.0.2\n",
            "I0808 19:27:08.389728 139645475628928 dataset_info.py:365] Load dataset info from /tmp/tmpz4b7n8nbtfds\n",
            "I0808 19:27:08.393116 139645475628928 dataset_info.py:424] Field info.citation from disk and from code do not match. Keeping the one from code.\n",
            "I0808 19:27:08.393588 139645475628928 dataset_info.py:424] Field info.splits from disk and from code do not match. Keeping the one from code.\n",
            "I0808 19:27:08.393742 139645475628928 dataset_info.py:424] Field info.module_name from disk and from code do not match. Keeping the one from code.\n",
            "I0808 19:27:08.394221 139645475628928 dataset_builder.py:400] Generating dataset cifar10 (/root/tensorflow_datasets/cifar10/3.0.2)\n",
            "\u001b[1mDownloading and preparing dataset 162.17 MiB (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to /root/tensorflow_datasets/cifar10/3.0.2...\u001b[0m\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0808 19:27:08.668737 139645475628928 download_manager.py:354] Downloading https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz into /root/tensorflow_datasets/downloads/cs.toronto.edu_kriz_cifar-10-binaryODHPtIjLh3oLcXirEISTO7dkzyKjRCuol6lV8Wc6C7s.tar.gz.tmp.9e314f006a6345caa9a897d6dbf5524a...\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   0% 0/162 [00:00<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   1% 1/162 [00:00<01:36,  1.67 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   1% 2/162 [00:00<01:35,  1.67 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   2% 3/162 [00:00<01:35,  1.67 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   2% 4/162 [00:00<00:23,  6.63 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   3% 5/162 [00:00<00:23,  6.63 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   4% 6/162 [00:00<00:23,  6.63 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   4% 7/162 [00:00<00:23,  6.63 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   5% 8/162 [00:00<00:23,  6.63 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   6% 9/162 [00:00<00:10, 15.02 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   6% 10/162 [00:00<00:10, 15.02 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   7% 11/162 [00:00<00:10, 15.02 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   7% 12/162 [00:00<00:09, 15.02 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   8% 13/162 [00:00<00:09, 15.02 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   9% 14/162 [00:00<00:06, 22.09 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...:   9% 15/162 [00:00<00:06, 22.09 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  10% 16/162 [00:01<00:06, 22.09 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  10% 17/162 [00:01<00:06, 22.09 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  11% 18/162 [00:01<00:06, 22.09 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  12% 19/162 [00:01<00:05, 26.89 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  12% 20/162 [00:01<00:05, 26.89 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  13% 21/162 [00:01<00:05, 26.89 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  14% 22/162 [00:01<00:05, 26.89 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  14% 23/162 [00:01<00:05, 26.89 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  15% 24/162 [00:01<00:04, 31.14 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  15% 25/162 [00:01<00:04, 31.14 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  16% 26/162 [00:01<00:04, 31.14 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  17% 27/162 [00:01<00:04, 31.14 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  17% 28/162 [00:01<00:04, 31.14 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  18% 29/162 [00:01<00:03, 34.74 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  19% 30/162 [00:01<00:03, 34.74 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  19% 31/162 [00:01<00:03, 34.74 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  20% 32/162 [00:01<00:03, 34.74 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  20% 33/162 [00:01<00:03, 34.74 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  21% 34/162 [00:01<00:03, 36.64 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  22% 35/162 [00:01<00:03, 36.64 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  22% 36/162 [00:01<00:03, 36.64 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  23% 37/162 [00:01<00:03, 36.64 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  23% 38/162 [00:01<00:03, 36.64 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  24% 39/162 [00:01<00:03, 38.11 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  25% 40/162 [00:01<00:03, 38.11 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  25% 41/162 [00:01<00:03, 38.11 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  26% 42/162 [00:01<00:03, 38.11 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  27% 43/162 [00:01<00:03, 38.11 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  27% 44/162 [00:01<00:03, 39.33 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  28% 45/162 [00:01<00:02, 39.33 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  28% 46/162 [00:01<00:02, 39.33 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  29% 47/162 [00:01<00:02, 39.33 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  30% 48/162 [00:01<00:02, 39.33 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  30% 49/162 [00:01<00:02, 40.83 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  31% 50/162 [00:01<00:02, 40.83 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  31% 51/162 [00:01<00:02, 40.83 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  32% 52/162 [00:01<00:02, 40.83 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  33% 53/162 [00:01<00:02, 40.83 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:01, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  33% 54/162 [00:01<00:02, 40.56 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  34% 55/162 [00:01<00:02, 40.56 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  35% 56/162 [00:01<00:02, 40.56 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:01<?, ? url/s]\n",
            "Dl Size...:  35% 57/162 [00:01<00:02, 40.56 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  36% 58/162 [00:02<00:02, 40.56 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  36% 59/162 [00:02<00:02, 42.23 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  37% 60/162 [00:02<00:02, 42.23 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  38% 61/162 [00:02<00:02, 42.23 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  38% 62/162 [00:02<00:02, 42.23 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  39% 63/162 [00:02<00:02, 42.23 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  40% 64/162 [00:02<00:02, 41.31 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  40% 65/162 [00:02<00:02, 41.31 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  41% 66/162 [00:02<00:02, 41.31 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  41% 67/162 [00:02<00:02, 41.31 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  42% 68/162 [00:02<00:02, 41.31 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  43% 69/162 [00:02<00:02, 42.19 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  43% 70/162 [00:02<00:02, 42.19 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  44% 71/162 [00:02<00:02, 42.19 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  44% 72/162 [00:02<00:02, 42.19 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  45% 73/162 [00:02<00:02, 42.19 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  46% 74/162 [00:02<00:02, 42.41 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  46% 75/162 [00:02<00:02, 42.41 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  47% 76/162 [00:02<00:02, 42.41 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  48% 77/162 [00:02<00:02, 42.41 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  48% 78/162 [00:02<00:01, 42.41 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  49% 79/162 [00:02<00:01, 42.44 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  49% 80/162 [00:02<00:01, 42.44 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  50% 81/162 [00:02<00:01, 42.44 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  51% 82/162 [00:02<00:01, 42.44 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  51% 83/162 [00:02<00:01, 42.44 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  52% 84/162 [00:02<00:01, 42.72 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  52% 85/162 [00:02<00:01, 42.72 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  53% 86/162 [00:02<00:01, 42.72 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  54% 87/162 [00:02<00:01, 42.72 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  54% 88/162 [00:02<00:01, 42.72 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  55% 89/162 [00:02<00:01, 42.96 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  56% 90/162 [00:02<00:01, 42.96 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  56% 91/162 [00:02<00:01, 42.96 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  57% 92/162 [00:02<00:01, 42.96 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  57% 93/162 [00:02<00:01, 42.96 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  58% 94/162 [00:02<00:01, 43.00 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  59% 95/162 [00:02<00:01, 43.00 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  59% 96/162 [00:02<00:01, 43.00 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  60% 97/162 [00:02<00:01, 43.00 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  60% 98/162 [00:02<00:01, 43.00 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  61% 99/162 [00:02<00:01, 42.47 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:02<?, ? url/s]\n",
            "Dl Size...:  62% 100/162 [00:02<00:01, 42.47 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  62% 101/162 [00:03<00:01, 42.47 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  63% 102/162 [00:03<00:01, 42.47 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  64% 103/162 [00:03<00:01, 42.47 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  64% 104/162 [00:03<00:01, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  65% 105/162 [00:03<00:01, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  65% 106/162 [00:03<00:01, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  66% 107/162 [00:03<00:01, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  67% 108/162 [00:03<00:01, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  67% 109/162 [00:03<00:01, 41.96 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  68% 110/162 [00:03<00:01, 41.96 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  69% 111/162 [00:03<00:01, 41.96 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  69% 112/162 [00:03<00:01, 41.96 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  70% 113/162 [00:03<00:01, 41.96 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  70% 114/162 [00:03<00:01, 42.21 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  71% 115/162 [00:03<00:01, 42.21 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  72% 116/162 [00:03<00:01, 42.21 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  72% 117/162 [00:03<00:01, 42.21 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  73% 118/162 [00:03<00:01, 42.21 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  73% 119/162 [00:03<00:01, 42.42 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  74% 120/162 [00:03<00:00, 42.42 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  75% 121/162 [00:03<00:00, 42.42 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  75% 122/162 [00:03<00:00, 42.42 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  76% 123/162 [00:03<00:00, 42.42 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  77% 124/162 [00:03<00:00, 43.72 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  77% 125/162 [00:03<00:00, 43.72 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  78% 126/162 [00:03<00:00, 43.72 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  78% 127/162 [00:03<00:00, 43.72 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  79% 128/162 [00:03<00:00, 43.72 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  80% 129/162 [00:03<00:00, 43.39 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  80% 130/162 [00:03<00:00, 43.39 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  81% 131/162 [00:03<00:00, 43.39 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  81% 132/162 [00:03<00:00, 43.39 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  82% 133/162 [00:03<00:00, 43.39 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  83% 134/162 [00:03<00:00, 44.93 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  83% 135/162 [00:03<00:00, 44.93 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  84% 136/162 [00:03<00:00, 44.93 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  85% 137/162 [00:03<00:00, 44.93 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  85% 138/162 [00:03<00:00, 44.93 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  86% 139/162 [00:03<00:00, 44.75 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  86% 140/162 [00:03<00:00, 44.75 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  87% 141/162 [00:03<00:00, 44.75 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  88% 142/162 [00:03<00:00, 44.75 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  88% 143/162 [00:03<00:00, 44.75 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:03, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:03<?, ? url/s]\n",
            "Dl Size...:  89% 144/162 [00:03<00:00, 45.83 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  90% 145/162 [00:04<00:00, 45.83 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  90% 146/162 [00:04<00:00, 45.83 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  91% 147/162 [00:04<00:00, 45.83 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  91% 148/162 [00:04<00:00, 45.83 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  92% 149/162 [00:04<00:00, 42.63 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  93% 150/162 [00:04<00:00, 42.63 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  93% 151/162 [00:04<00:00, 42.63 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  94% 152/162 [00:04<00:00, 42.63 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  94% 153/162 [00:04<00:00, 42.63 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  95% 154/162 [00:04<00:00, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  96% 155/162 [00:04<00:00, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  96% 156/162 [00:04<00:00, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  97% 157/162 [00:04<00:00, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  98% 158/162 [00:04<00:00, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  98% 159/162 [00:04<00:00, 42.97 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:04, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  99% 160/162 [00:04<00:00, 43.80 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:  99% 161/162 [00:04<00:00, 43.80 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...: 100% 162/162 [00:04<00:00, 43.80 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:04<00:00,  4.41s/ url]\n",
            "Dl Size...: 100% 162/162 [00:04<00:00, 43.80 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:04<00:00,  4.41s/ url]\n",
            "Dl Size...: 100% 162/162 [00:04<00:00, 43.80 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...:   0% 0/1 [00:04<?, ? file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:06<00:00,  4.41s/ url]\n",
            "Dl Size...: 100% 162/162 [00:06<00:00, 43.80 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100% 1/1 [00:06<00:00,  6.85s/ file]\n",
            "Dl Size...: 100% 162/162 [00:06<00:00, 23.66 MiB/s]\n",
            "Dl Completed...: 100% 1/1 [00:06<00:00,  6.85s/ url]\n",
            "Generating splits...:   0% 0/2 [00:00<?, ? splits/s]\n",
            "Generating train examples...:   0% 0/50000 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating train examples...:   0% 44/50000 [00:00<01:54, 436.87 examples/s]\u001b[A\n",
            "Generating train examples...:   0% 207/50000 [00:00<00:44, 1127.82 examples/s]\u001b[A\n",
            "Generating train examples...:   1% 363/50000 [00:00<00:37, 1321.22 examples/s]\u001b[A\n",
            "Generating train examples...:   1% 530/50000 [00:00<00:33, 1457.90 examples/s]\u001b[A\n",
            "Generating train examples...:   1% 688/50000 [00:00<00:32, 1498.71 examples/s]\u001b[A\n",
            "Generating train examples...:   2% 839/50000 [00:00<00:32, 1501.60 examples/s]\u001b[A\n",
            "Generating train examples...:   2% 990/50000 [00:00<00:32, 1499.75 examples/s]\u001b[A\n",
            "Generating train examples...:   2% 1143/50000 [00:00<00:32, 1509.29 examples/s]\u001b[A\n",
            "Generating train examples...:   3% 1294/50000 [00:00<00:32, 1508.96 examples/s]\u001b[A\n",
            "Generating train examples...:   3% 1445/50000 [00:01<00:34, 1424.58 examples/s]\u001b[A\n",
            "Generating train examples...:   3% 1589/50000 [00:01<00:34, 1414.61 examples/s]\u001b[A\n",
            "Generating train examples...:   3% 1743/50000 [00:01<00:33, 1450.10 examples/s]\u001b[A\n",
            "Generating train examples...:   4% 1889/50000 [00:01<00:36, 1329.79 examples/s]\u001b[A\n",
            "Generating train examples...:   4% 2025/50000 [00:01<00:37, 1270.77 examples/s]\u001b[A\n",
            "Generating train examples...:   4% 2154/50000 [00:01<00:39, 1217.28 examples/s]\u001b[A\n",
            "Generating train examples...:   5% 2278/50000 [00:01<00:40, 1190.62 examples/s]\u001b[A\n",
            "Generating train examples...:   5% 2398/50000 [00:01<00:40, 1188.46 examples/s]\u001b[A\n",
            "Generating train examples...:   5% 2518/50000 [00:01<00:40, 1170.21 examples/s]\u001b[A\n",
            "Generating train examples...:   5% 2636/50000 [00:02<00:41, 1150.06 examples/s]\u001b[A\n",
            "Generating train examples...:   6% 2752/50000 [00:02<00:43, 1097.09 examples/s]\u001b[A\n",
            "Generating train examples...:   6% 2863/50000 [00:02<00:44, 1062.94 examples/s]\u001b[A\n",
            "Generating train examples...:   6% 2972/50000 [00:02<00:44, 1068.76 examples/s]\u001b[A\n",
            "Generating train examples...:   6% 3080/50000 [00:02<00:47, 996.93 examples/s] \u001b[A\n",
            "Generating train examples...:   6% 3186/50000 [00:02<00:46, 1011.77 examples/s]\u001b[A\n",
            "Generating train examples...:   7% 3302/50000 [00:02<00:44, 1051.21 examples/s]\u001b[A\n",
            "Generating train examples...:   7% 3417/50000 [00:02<00:43, 1078.04 examples/s]\u001b[A\n",
            "Generating train examples...:   7% 3531/50000 [00:02<00:42, 1093.78 examples/s]\u001b[A\n",
            "Generating train examples...:   7% 3675/50000 [00:02<00:38, 1193.97 examples/s]\u001b[A\n",
            "Generating train examples...:   8% 3822/50000 [00:03<00:36, 1274.43 examples/s]\u001b[A\n",
            "Generating train examples...:   8% 3967/50000 [00:03<00:34, 1324.92 examples/s]\u001b[A\n",
            "Generating train examples...:   8% 4128/50000 [00:03<00:32, 1407.29 examples/s]\u001b[A\n",
            "Generating train examples...:   9% 4281/50000 [00:03<00:31, 1442.85 examples/s]\u001b[A\n",
            "Generating train examples...:   9% 4444/50000 [00:03<00:30, 1496.70 examples/s]\u001b[A\n",
            "Generating train examples...:   9% 4600/50000 [00:03<00:29, 1514.22 examples/s]\u001b[A\n",
            "Generating train examples...:  10% 4754/50000 [00:03<00:29, 1520.41 examples/s]\u001b[A\n",
            "Generating train examples...:  10% 4917/50000 [00:03<00:29, 1550.55 examples/s]\u001b[A\n",
            "Generating train examples...:  10% 5073/50000 [00:03<00:29, 1542.86 examples/s]\u001b[A\n",
            "Generating train examples...:  10% 5228/50000 [00:03<00:29, 1531.31 examples/s]\u001b[A\n",
            "Generating train examples...:  11% 5385/50000 [00:04<00:28, 1540.36 examples/s]\u001b[A\n",
            "Generating train examples...:  11% 5540/50000 [00:04<00:29, 1499.48 examples/s]\u001b[A\n",
            "Generating train examples...:  11% 5697/50000 [00:04<00:29, 1518.07 examples/s]\u001b[A\n",
            "Generating train examples...:  12% 5850/50000 [00:04<00:29, 1513.93 examples/s]\u001b[A\n",
            "Generating train examples...:  12% 6004/50000 [00:04<00:28, 1519.93 examples/s]\u001b[A\n",
            "Generating train examples...:  12% 6157/50000 [00:04<00:28, 1522.07 examples/s]\u001b[A\n",
            "Generating train examples...:  13% 6324/50000 [00:04<00:27, 1563.16 examples/s]\u001b[A\n",
            "Generating train examples...:  13% 6481/50000 [00:04<00:27, 1564.50 examples/s]\u001b[A\n",
            "Generating train examples...:  13% 6644/50000 [00:04<00:27, 1581.49 examples/s]\u001b[A\n",
            "Generating train examples...:  14% 6803/50000 [00:05<00:27, 1579.04 examples/s]\u001b[A\n",
            "Generating train examples...:  14% 6963/50000 [00:05<00:27, 1585.00 examples/s]\u001b[A\n",
            "Generating train examples...:  14% 7122/50000 [00:05<00:27, 1565.23 examples/s]\u001b[A\n",
            "Generating train examples...:  15% 7283/50000 [00:05<00:27, 1577.39 examples/s]\u001b[A\n",
            "Generating train examples...:  15% 7447/50000 [00:05<00:26, 1594.88 examples/s]\u001b[A\n",
            "Generating train examples...:  15% 7613/50000 [00:05<00:26, 1612.60 examples/s]\u001b[A\n",
            "Generating train examples...:  16% 7775/50000 [00:05<00:26, 1594.35 examples/s]\u001b[A\n",
            "Generating train examples...:  16% 7943/50000 [00:05<00:25, 1619.01 examples/s]\u001b[A\n",
            "Generating train examples...:  16% 8105/50000 [00:05<00:25, 1614.02 examples/s]\u001b[A\n",
            "Generating train examples...:  17% 8267/50000 [00:05<00:25, 1609.98 examples/s]\u001b[A\n",
            "Generating train examples...:  17% 8429/50000 [00:06<00:25, 1603.59 examples/s]\u001b[A\n",
            "Generating train examples...:  17% 8591/50000 [00:06<00:25, 1608.39 examples/s]\u001b[A\n",
            "Generating train examples...:  18% 8752/50000 [00:06<00:26, 1576.75 examples/s]\u001b[A\n",
            "Generating train examples...:  18% 8919/50000 [00:06<00:25, 1603.48 examples/s]\u001b[A\n",
            "Generating train examples...:  18% 9086/50000 [00:06<00:25, 1621.94 examples/s]\u001b[A\n",
            "Generating train examples...:  18% 9249/50000 [00:06<00:25, 1606.73 examples/s]\u001b[A\n",
            "Generating train examples...:  19% 9412/50000 [00:06<00:25, 1611.69 examples/s]\u001b[A\n",
            "Generating train examples...:  19% 9574/50000 [00:06<00:25, 1582.22 examples/s]\u001b[A\n",
            "Generating train examples...:  19% 9735/50000 [00:06<00:25, 1588.58 examples/s]\u001b[A\n",
            "Generating train examples...:  20% 9899/50000 [00:06<00:25, 1603.14 examples/s]\u001b[A\n",
            "Generating train examples...:  20% 10060/50000 [00:07<00:31, 1266.99 examples/s]\u001b[A\n",
            "Generating train examples...:  20% 10209/50000 [00:07<00:30, 1320.96 examples/s]\u001b[A\n",
            "Generating train examples...:  21% 10370/50000 [00:07<00:28, 1395.54 examples/s]\u001b[A\n",
            "Generating train examples...:  21% 10528/50000 [00:07<00:27, 1444.19 examples/s]\u001b[A\n",
            "Generating train examples...:  21% 10682/50000 [00:07<00:26, 1470.15 examples/s]\u001b[A\n",
            "Generating train examples...:  22% 10834/50000 [00:07<00:26, 1472.85 examples/s]\u001b[A\n",
            "Generating train examples...:  22% 10998/50000 [00:07<00:25, 1520.30 examples/s]\u001b[A\n",
            "Generating train examples...:  22% 11165/50000 [00:07<00:24, 1562.92 examples/s]\u001b[A\n",
            "Generating train examples...:  23% 11323/50000 [00:07<00:25, 1534.85 examples/s]\u001b[A\n",
            "Generating train examples...:  23% 11483/50000 [00:08<00:24, 1552.72 examples/s]\u001b[A\n",
            "Generating train examples...:  23% 11640/50000 [00:08<00:24, 1548.53 examples/s]\u001b[A\n",
            "Generating train examples...:  24% 11796/50000 [00:08<00:25, 1478.23 examples/s]\u001b[A\n",
            "Generating train examples...:  24% 11948/50000 [00:08<00:25, 1489.66 examples/s]\u001b[A\n",
            "Generating train examples...:  24% 12103/50000 [00:08<00:25, 1505.78 examples/s]\u001b[A\n",
            "Generating train examples...:  25% 12255/50000 [00:08<00:25, 1489.50 examples/s]\u001b[A\n",
            "Generating train examples...:  25% 12422/50000 [00:08<00:24, 1540.36 examples/s]\u001b[A\n",
            "Generating train examples...:  25% 12584/50000 [00:08<00:23, 1563.24 examples/s]\u001b[A\n",
            "Generating train examples...:  26% 12753/50000 [00:08<00:23, 1597.91 examples/s]\u001b[A\n",
            "Generating train examples...:  26% 12914/50000 [00:08<00:23, 1597.74 examples/s]\u001b[A\n",
            "Generating train examples...:  26% 13074/50000 [00:09<00:23, 1587.55 examples/s]\u001b[A\n",
            "Generating train examples...:  26% 13236/50000 [00:09<00:23, 1596.28 examples/s]\u001b[A\n",
            "Generating train examples...:  27% 13398/50000 [00:09<00:22, 1600.76 examples/s]\u001b[A\n",
            "Generating train examples...:  27% 13559/50000 [00:09<00:22, 1589.24 examples/s]\u001b[A\n",
            "Generating train examples...:  27% 13718/50000 [00:09<00:22, 1584.30 examples/s]\u001b[A\n",
            "Generating train examples...:  28% 13877/50000 [00:09<00:22, 1581.99 examples/s]\u001b[A\n",
            "Generating train examples...:  28% 14036/50000 [00:09<00:22, 1580.30 examples/s]\u001b[A\n",
            "Generating train examples...:  28% 14195/50000 [00:09<00:22, 1577.47 examples/s]\u001b[A\n",
            "Generating train examples...:  29% 14355/50000 [00:09<00:22, 1583.26 examples/s]\u001b[A\n",
            "Generating train examples...:  29% 14514/50000 [00:09<00:22, 1548.57 examples/s]\u001b[A\n",
            "Generating train examples...:  29% 14673/50000 [00:10<00:22, 1558.77 examples/s]\u001b[A\n",
            "Generating train examples...:  30% 14830/50000 [00:10<00:22, 1542.73 examples/s]\u001b[A\n",
            "Generating train examples...:  30% 14985/50000 [00:10<00:22, 1528.78 examples/s]\u001b[A\n",
            "Generating train examples...:  30% 15138/50000 [00:10<00:22, 1524.09 examples/s]\u001b[A\n",
            "Generating train examples...:  31% 15297/50000 [00:10<00:22, 1542.01 examples/s]\u001b[A\n",
            "Generating train examples...:  31% 15462/50000 [00:10<00:21, 1571.69 examples/s]\u001b[A\n",
            "Generating train examples...:  31% 15620/50000 [00:10<00:22, 1524.65 examples/s]\u001b[A\n",
            "Generating train examples...:  32% 15782/50000 [00:10<00:22, 1551.00 examples/s]\u001b[A\n",
            "Generating train examples...:  32% 15943/50000 [00:10<00:21, 1566.92 examples/s]\u001b[A\n",
            "Generating train examples...:  32% 16100/50000 [00:11<00:21, 1561.48 examples/s]\u001b[A\n",
            "Generating train examples...:  33% 16257/50000 [00:11<00:21, 1553.55 examples/s]\u001b[A\n",
            "Generating train examples...:  33% 16413/50000 [00:11<00:21, 1544.19 examples/s]\u001b[A\n",
            "Generating train examples...:  33% 16568/50000 [00:11<00:21, 1534.35 examples/s]\u001b[A\n",
            "Generating train examples...:  33% 16722/50000 [00:11<00:22, 1452.22 examples/s]\u001b[A\n",
            "Generating train examples...:  34% 16882/50000 [00:11<00:22, 1494.23 examples/s]\u001b[A\n",
            "Generating train examples...:  34% 17042/50000 [00:11<00:21, 1522.55 examples/s]\u001b[A\n",
            "Generating train examples...:  34% 17200/50000 [00:11<00:21, 1537.78 examples/s]\u001b[A\n",
            "Generating train examples...:  35% 17355/50000 [00:11<00:22, 1482.91 examples/s]\u001b[A\n",
            "Generating train examples...:  35% 17509/50000 [00:11<00:21, 1497.80 examples/s]\u001b[A\n",
            "Generating train examples...:  35% 17665/50000 [00:12<00:21, 1514.86 examples/s]\u001b[A\n",
            "Generating train examples...:  36% 17828/50000 [00:12<00:20, 1546.50 examples/s]\u001b[A\n",
            "Generating train examples...:  36% 17994/50000 [00:12<00:20, 1579.55 examples/s]\u001b[A\n",
            "Generating train examples...:  36% 18153/50000 [00:12<00:20, 1540.74 examples/s]\u001b[A\n",
            "Generating train examples...:  37% 18315/50000 [00:12<00:20, 1563.84 examples/s]\u001b[A\n",
            "Generating train examples...:  37% 18477/50000 [00:12<00:19, 1579.57 examples/s]\u001b[A\n",
            "Generating train examples...:  37% 18636/50000 [00:12<00:19, 1571.76 examples/s]\u001b[A\n",
            "Generating train examples...:  38% 18797/50000 [00:12<00:19, 1582.42 examples/s]\u001b[A\n",
            "Generating train examples...:  38% 18956/50000 [00:12<00:19, 1571.24 examples/s]\u001b[A\n",
            "Generating train examples...:  38% 19114/50000 [00:12<00:19, 1544.78 examples/s]\u001b[A\n",
            "Generating train examples...:  39% 19272/50000 [00:13<00:19, 1552.74 examples/s]\u001b[A\n",
            "Generating train examples...:  39% 19428/50000 [00:13<00:19, 1538.30 examples/s]\u001b[A\n",
            "Generating train examples...:  39% 19593/50000 [00:13<00:19, 1570.69 examples/s]\u001b[A\n",
            "Generating train examples...:  40% 19751/50000 [00:13<00:19, 1564.93 examples/s]\u001b[A\n",
            "Generating train examples...:  40% 19908/50000 [00:13<00:19, 1546.63 examples/s]\u001b[A\n",
            "Generating train examples...:  40% 20063/50000 [00:13<00:23, 1291.94 examples/s]\u001b[A\n",
            "Generating train examples...:  40% 20228/50000 [00:13<00:21, 1383.19 examples/s]\u001b[A\n",
            "Generating train examples...:  41% 20389/50000 [00:13<00:20, 1443.23 examples/s]\u001b[A\n",
            "Generating train examples...:  41% 20548/50000 [00:13<00:19, 1481.15 examples/s]\u001b[A\n",
            "Generating train examples...:  41% 20709/50000 [00:14<00:19, 1516.29 examples/s]\u001b[A\n",
            "Generating train examples...:  42% 20868/50000 [00:14<00:18, 1536.01 examples/s]\u001b[A\n",
            "Generating train examples...:  42% 21024/50000 [00:14<00:19, 1507.86 examples/s]\u001b[A\n",
            "Generating train examples...:  42% 21184/50000 [00:14<00:18, 1533.76 examples/s]\u001b[A\n",
            "Generating train examples...:  43% 21339/50000 [00:14<00:19, 1490.91 examples/s]\u001b[A\n",
            "Generating train examples...:  43% 21499/50000 [00:14<00:18, 1521.44 examples/s]\u001b[A\n",
            "Generating train examples...:  43% 21655/50000 [00:14<00:18, 1530.38 examples/s]\u001b[A\n",
            "Generating train examples...:  44% 21814/50000 [00:14<00:18, 1547.04 examples/s]\u001b[A\n",
            "Generating train examples...:  44% 21974/50000 [00:14<00:17, 1561.73 examples/s]\u001b[A\n",
            "Generating train examples...:  44% 22131/50000 [00:14<00:18, 1540.94 examples/s]\u001b[A\n",
            "Generating train examples...:  45% 22286/50000 [00:15<00:17, 1543.28 examples/s]\u001b[A\n",
            "Generating train examples...:  45% 22441/50000 [00:15<00:17, 1537.79 examples/s]\u001b[A\n",
            "Generating train examples...:  45% 22606/50000 [00:15<00:17, 1569.75 examples/s]\u001b[A\n",
            "Generating train examples...:  46% 22769/50000 [00:15<00:17, 1586.16 examples/s]\u001b[A\n",
            "Generating train examples...:  46% 22928/50000 [00:15<00:17, 1520.88 examples/s]\u001b[A\n",
            "Generating train examples...:  46% 23088/50000 [00:15<00:17, 1542.72 examples/s]\u001b[A\n",
            "Generating train examples...:  46% 23243/50000 [00:15<00:17, 1539.32 examples/s]\u001b[A\n",
            "Generating train examples...:  47% 23400/50000 [00:15<00:17, 1547.17 examples/s]\u001b[A\n",
            "Generating train examples...:  47% 23559/50000 [00:15<00:16, 1559.13 examples/s]\u001b[A\n",
            "Generating train examples...:  47% 23716/50000 [00:15<00:16, 1549.19 examples/s]\u001b[A\n",
            "Generating train examples...:  48% 23878/50000 [00:16<00:16, 1569.94 examples/s]\u001b[A\n",
            "Generating train examples...:  48% 24041/50000 [00:16<00:16, 1585.71 examples/s]\u001b[A\n",
            "Generating train examples...:  48% 24200/50000 [00:16<00:16, 1586.54 examples/s]\u001b[A\n",
            "Generating train examples...:  49% 24363/50000 [00:16<00:16, 1599.03 examples/s]\u001b[A\n",
            "Generating train examples...:  49% 24523/50000 [00:16<00:16, 1572.25 examples/s]\u001b[A\n",
            "Generating train examples...:  49% 24681/50000 [00:16<00:16, 1558.34 examples/s]\u001b[A\n",
            "Generating train examples...:  50% 24847/50000 [00:16<00:15, 1586.69 examples/s]\u001b[A\n",
            "Generating train examples...:  50% 25006/50000 [00:16<00:16, 1560.53 examples/s]\u001b[A\n",
            "Generating train examples...:  50% 25163/50000 [00:16<00:16, 1496.39 examples/s]\u001b[A\n",
            "Generating train examples...:  51% 25324/50000 [00:17<00:16, 1528.90 examples/s]\u001b[A\n",
            "Generating train examples...:  51% 25488/50000 [00:17<00:15, 1560.23 examples/s]\u001b[A\n",
            "Generating train examples...:  51% 25645/50000 [00:17<00:15, 1555.00 examples/s]\u001b[A\n",
            "Generating train examples...:  52% 25803/50000 [00:17<00:15, 1560.55 examples/s]\u001b[A\n",
            "Generating train examples...:  52% 25968/50000 [00:17<00:15, 1586.23 examples/s]\u001b[A\n",
            "Generating train examples...:  52% 26127/50000 [00:17<00:15, 1547.23 examples/s]\u001b[A\n",
            "Generating train examples...:  53% 26292/50000 [00:17<00:15, 1574.72 examples/s]\u001b[A\n",
            "Generating train examples...:  53% 26452/50000 [00:17<00:14, 1579.93 examples/s]\u001b[A\n",
            "Generating train examples...:  53% 26611/50000 [00:17<00:14, 1563.03 examples/s]\u001b[A\n",
            "Generating train examples...:  54% 26768/50000 [00:17<00:14, 1560.16 examples/s]\u001b[A\n",
            "Generating train examples...:  54% 26926/50000 [00:18<00:14, 1562.40 examples/s]\u001b[A\n",
            "Generating train examples...:  54% 27083/50000 [00:18<00:14, 1528.33 examples/s]\u001b[A\n",
            "Generating train examples...:  54% 27243/50000 [00:18<00:14, 1548.70 examples/s]\u001b[A\n",
            "Generating train examples...:  55% 27407/50000 [00:18<00:14, 1573.76 examples/s]\u001b[A\n",
            "Generating train examples...:  55% 27565/50000 [00:18<00:14, 1545.08 examples/s]\u001b[A\n",
            "Generating train examples...:  55% 27720/50000 [00:18<00:14, 1525.11 examples/s]\u001b[A\n",
            "Generating train examples...:  56% 27873/50000 [00:18<00:14, 1515.36 examples/s]\u001b[A\n",
            "Generating train examples...:  56% 28029/50000 [00:18<00:14, 1527.10 examples/s]\u001b[A\n",
            "Generating train examples...:  56% 28189/50000 [00:18<00:14, 1547.68 examples/s]\u001b[A\n",
            "Generating train examples...:  57% 28344/50000 [00:18<00:14, 1535.76 examples/s]\u001b[A\n",
            "Generating train examples...:  57% 28498/50000 [00:19<00:14, 1535.28 examples/s]\u001b[A\n",
            "Generating train examples...:  57% 28652/50000 [00:19<00:14, 1518.81 examples/s]\u001b[A\n",
            "Generating train examples...:  58% 28805/50000 [00:19<00:13, 1520.72 examples/s]\u001b[A\n",
            "Generating train examples...:  58% 28959/50000 [00:19<00:13, 1524.18 examples/s]\u001b[A\n",
            "Generating train examples...:  58% 29112/50000 [00:19<00:13, 1512.20 examples/s]\u001b[A\n",
            "Generating train examples...:  59% 29264/50000 [00:19<00:13, 1496.65 examples/s]\u001b[A\n",
            "Generating train examples...:  59% 29430/50000 [00:19<00:13, 1542.05 examples/s]\u001b[A\n",
            "Generating train examples...:  59% 29585/50000 [00:19<00:13, 1542.57 examples/s]\u001b[A\n",
            "Generating train examples...:  60% 29751/50000 [00:19<00:12, 1575.20 examples/s]\u001b[A\n",
            "Generating train examples...:  60% 29910/50000 [00:19<00:12, 1579.12 examples/s]\u001b[A\n",
            "Generating train examples...:  60% 30068/50000 [00:20<00:15, 1280.45 examples/s]\u001b[A\n",
            "Generating train examples...:  60% 30229/50000 [00:20<00:14, 1363.69 examples/s]\u001b[A\n",
            "Generating train examples...:  61% 30390/50000 [00:20<00:13, 1428.97 examples/s]\u001b[A\n",
            "Generating train examples...:  61% 30540/50000 [00:20<00:13, 1441.29 examples/s]\u001b[A\n",
            "Generating train examples...:  61% 30689/50000 [00:20<00:13, 1449.12 examples/s]\u001b[A\n",
            "Generating train examples...:  62% 30855/50000 [00:20<00:12, 1509.24 examples/s]\u001b[A\n",
            "Generating train examples...:  62% 31011/50000 [00:20<00:12, 1523.09 examples/s]\u001b[A\n",
            "Generating train examples...:  62% 31169/50000 [00:20<00:12, 1537.50 examples/s]\u001b[A\n",
            "Generating train examples...:  63% 31325/50000 [00:20<00:12, 1528.07 examples/s]\u001b[A\n",
            "Generating train examples...:  63% 31480/50000 [00:21<00:12, 1533.96 examples/s]\u001b[A\n",
            "Generating train examples...:  63% 31635/50000 [00:21<00:11, 1531.81 examples/s]\u001b[A\n",
            "Generating train examples...:  64% 31789/50000 [00:21<00:12, 1514.29 examples/s]\u001b[A\n",
            "Generating train examples...:  64% 31948/50000 [00:21<00:11, 1535.70 examples/s]\u001b[A\n",
            "Generating train examples...:  64% 32102/50000 [00:21<00:11, 1492.70 examples/s]\u001b[A\n",
            "Generating train examples...:  65% 32252/50000 [00:21<00:12, 1472.04 examples/s]\u001b[A\n",
            "Generating train examples...:  65% 32412/50000 [00:21<00:11, 1507.55 examples/s]\u001b[A\n",
            "Generating train examples...:  65% 32564/50000 [00:21<00:11, 1511.05 examples/s]\u001b[A\n",
            "Generating train examples...:  65% 32727/50000 [00:21<00:11, 1545.76 examples/s]\u001b[A\n",
            "Generating train examples...:  66% 32882/50000 [00:22<00:11, 1529.50 examples/s]\u001b[A\n",
            "Generating train examples...:  66% 33044/50000 [00:22<00:10, 1554.91 examples/s]\u001b[A\n",
            "Generating train examples...:  66% 33206/50000 [00:22<00:10, 1573.56 examples/s]\u001b[A\n",
            "Generating train examples...:  67% 33364/50000 [00:22<00:10, 1519.72 examples/s]\u001b[A\n",
            "Generating train examples...:  67% 33530/50000 [00:22<00:10, 1558.49 examples/s]\u001b[A\n",
            "Generating train examples...:  67% 33696/50000 [00:22<00:10, 1587.01 examples/s]\u001b[A\n",
            "Generating train examples...:  68% 33856/50000 [00:22<00:10, 1540.54 examples/s]\u001b[A\n",
            "Generating train examples...:  68% 34021/50000 [00:22<00:10, 1570.92 examples/s]\u001b[A\n",
            "Generating train examples...:  68% 34186/50000 [00:22<00:09, 1593.90 examples/s]\u001b[A\n",
            "Generating train examples...:  69% 34350/50000 [00:22<00:09, 1606.93 examples/s]\u001b[A\n",
            "Generating train examples...:  69% 34511/50000 [00:23<00:09, 1589.51 examples/s]\u001b[A\n",
            "Generating train examples...:  69% 34671/50000 [00:23<00:09, 1582.71 examples/s]\u001b[A\n",
            "Generating train examples...:  70% 34830/50000 [00:23<00:09, 1582.39 examples/s]\u001b[A\n",
            "Generating train examples...:  70% 34989/50000 [00:23<00:09, 1553.14 examples/s]\u001b[A\n",
            "Generating train examples...:  70% 35145/50000 [00:23<00:09, 1530.58 examples/s]\u001b[A\n",
            "Generating train examples...:  71% 35299/50000 [00:23<00:09, 1506.63 examples/s]\u001b[A\n",
            "Generating train examples...:  71% 35450/50000 [00:23<00:09, 1492.73 examples/s]\u001b[A\n",
            "Generating train examples...:  71% 35604/50000 [00:23<00:09, 1504.69 examples/s]\u001b[A\n",
            "Generating train examples...:  72% 35761/50000 [00:23<00:09, 1522.97 examples/s]\u001b[A\n",
            "Generating train examples...:  72% 35914/50000 [00:23<00:09, 1523.70 examples/s]\u001b[A\n",
            "Generating train examples...:  72% 36075/50000 [00:24<00:08, 1549.24 examples/s]\u001b[A\n",
            "Generating train examples...:  72% 36231/50000 [00:24<00:08, 1547.15 examples/s]\u001b[A\n",
            "Generating train examples...:  73% 36386/50000 [00:24<00:09, 1498.61 examples/s]\u001b[A\n",
            "Generating train examples...:  73% 36545/50000 [00:24<00:08, 1523.75 examples/s]\u001b[A\n",
            "Generating train examples...:  73% 36699/50000 [00:24<00:08, 1525.33 examples/s]\u001b[A\n",
            "Generating train examples...:  74% 36852/50000 [00:24<00:08, 1500.43 examples/s]\u001b[A\n",
            "Generating train examples...:  74% 37003/50000 [00:24<00:08, 1486.33 examples/s]\u001b[A\n",
            "Generating train examples...:  74% 37152/50000 [00:24<00:08, 1479.77 examples/s]\u001b[A\n",
            "Generating train examples...:  75% 37316/50000 [00:24<00:08, 1526.21 examples/s]\u001b[A\n",
            "Generating train examples...:  75% 37469/50000 [00:24<00:08, 1525.37 examples/s]\u001b[A\n",
            "Generating train examples...:  75% 37623/50000 [00:25<00:08, 1529.60 examples/s]\u001b[A\n",
            "Generating train examples...:  76% 37785/50000 [00:25<00:07, 1555.68 examples/s]\u001b[A\n",
            "Generating train examples...:  76% 37941/50000 [00:25<00:07, 1546.39 examples/s]\u001b[A\n",
            "Generating train examples...:  76% 38106/50000 [00:25<00:07, 1575.56 examples/s]\u001b[A\n",
            "Generating train examples...:  77% 38264/50000 [00:25<00:07, 1542.01 examples/s]\u001b[A\n",
            "Generating train examples...:  77% 38422/50000 [00:25<00:07, 1551.13 examples/s]\u001b[A\n",
            "Generating train examples...:  77% 38578/50000 [00:25<00:07, 1536.43 examples/s]\u001b[A\n",
            "Generating train examples...:  77% 38732/50000 [00:25<00:07, 1508.03 examples/s]\u001b[A\n",
            "Generating train examples...:  78% 38895/50000 [00:25<00:07, 1541.50 examples/s]\u001b[A\n",
            "Generating train examples...:  78% 39050/50000 [00:26<00:07, 1535.53 examples/s]\u001b[A\n",
            "Generating train examples...:  78% 39213/50000 [00:26<00:06, 1560.49 examples/s]\u001b[A\n",
            "Generating train examples...:  79% 39372/50000 [00:26<00:06, 1569.03 examples/s]\u001b[A\n",
            "Generating train examples...:  79% 39530/50000 [00:26<00:06, 1537.98 examples/s]\u001b[A\n",
            "Generating train examples...:  79% 39692/50000 [00:26<00:06, 1559.42 examples/s]\u001b[A\n",
            "Generating train examples...:  80% 39849/50000 [00:26<00:06, 1523.18 examples/s]\u001b[A\n",
            "Generating train examples...:  80% 40002/50000 [00:26<00:07, 1273.22 examples/s]\u001b[A\n",
            "Generating train examples...:  80% 40145/50000 [00:26<00:07, 1312.56 examples/s]\u001b[A\n",
            "Generating train examples...:  81% 40303/50000 [00:26<00:07, 1383.77 examples/s]\u001b[A\n",
            "Generating train examples...:  81% 40461/50000 [00:26<00:06, 1435.96 examples/s]\u001b[A\n",
            "Generating train examples...:  81% 40609/50000 [00:27<00:06, 1428.72 examples/s]\u001b[A\n",
            "Generating train examples...:  82% 40764/50000 [00:27<00:06, 1462.23 examples/s]\u001b[A\n",
            "Generating train examples...:  82% 40919/50000 [00:27<00:06, 1486.70 examples/s]\u001b[A\n",
            "Generating train examples...:  82% 41083/50000 [00:27<00:05, 1530.78 examples/s]\u001b[A\n",
            "Generating train examples...:  82% 41249/50000 [00:27<00:05, 1568.67 examples/s]\u001b[A\n",
            "Generating train examples...:  83% 41407/50000 [00:27<00:05, 1555.93 examples/s]\u001b[A\n",
            "Generating train examples...:  83% 41572/50000 [00:27<00:05, 1581.81 examples/s]\u001b[A\n",
            "Generating train examples...:  83% 41731/50000 [00:27<00:05, 1574.97 examples/s]\u001b[A\n",
            "Generating train examples...:  84% 41889/50000 [00:27<00:05, 1571.68 examples/s]\u001b[A\n",
            "Generating train examples...:  84% 42052/50000 [00:28<00:05, 1586.40 examples/s]\u001b[A\n",
            "Generating train examples...:  84% 42211/50000 [00:28<00:04, 1561.89 examples/s]\u001b[A\n",
            "Generating train examples...:  85% 42379/50000 [00:28<00:04, 1594.12 examples/s]\u001b[A\n",
            "Generating train examples...:  85% 42548/50000 [00:28<00:04, 1621.95 examples/s]\u001b[A\n",
            "Generating train examples...:  85% 42711/50000 [00:28<00:04, 1588.23 examples/s]\u001b[A\n",
            "Generating train examples...:  86% 42873/50000 [00:28<00:04, 1595.86 examples/s]\u001b[A\n",
            "Generating train examples...:  86% 43036/50000 [00:28<00:04, 1604.99 examples/s]\u001b[A\n",
            "Generating train examples...:  86% 43197/50000 [00:28<00:04, 1589.73 examples/s]\u001b[A\n",
            "Generating train examples...:  87% 43357/50000 [00:28<00:04, 1567.38 examples/s]\u001b[A\n",
            "Generating train examples...:  87% 43522/50000 [00:28<00:04, 1589.99 examples/s]\u001b[A\n",
            "Generating train examples...:  87% 43682/50000 [00:29<00:04, 1574.68 examples/s]\u001b[A\n",
            "Generating train examples...:  88% 43846/50000 [00:29<00:03, 1592.14 examples/s]\u001b[A\n",
            "Generating train examples...:  88% 44007/50000 [00:29<00:03, 1595.95 examples/s]\u001b[A\n",
            "Generating train examples...:  88% 44167/50000 [00:29<00:03, 1575.06 examples/s]\u001b[A\n",
            "Generating train examples...:  89% 44325/50000 [00:29<00:03, 1575.69 examples/s]\u001b[A\n",
            "Generating train examples...:  89% 44483/50000 [00:29<00:03, 1550.00 examples/s]\u001b[A\n",
            "Generating train examples...:  89% 44643/50000 [00:29<00:03, 1562.23 examples/s]\u001b[A\n",
            "Generating train examples...:  90% 44805/50000 [00:29<00:03, 1576.93 examples/s]\u001b[A\n",
            "Generating train examples...:  90% 44963/50000 [00:29<00:03, 1523.67 examples/s]\u001b[A\n",
            "Generating train examples...:  90% 45122/50000 [00:29<00:03, 1541.44 examples/s]\u001b[A\n",
            "Generating train examples...:  91% 45277/50000 [00:30<00:03, 1525.64 examples/s]\u001b[A\n",
            "Generating train examples...:  91% 45440/50000 [00:30<00:02, 1555.62 examples/s]\u001b[A\n",
            "Generating train examples...:  91% 45599/50000 [00:30<00:02, 1563.83 examples/s]\u001b[A\n",
            "Generating train examples...:  92% 45756/50000 [00:30<00:02, 1479.08 examples/s]\u001b[A\n",
            "Generating train examples...:  92% 45915/50000 [00:30<00:02, 1510.04 examples/s]\u001b[A\n",
            "Generating train examples...:  92% 46079/50000 [00:30<00:02, 1547.25 examples/s]\u001b[A\n",
            "Generating train examples...:  92% 46235/50000 [00:30<00:02, 1531.30 examples/s]\u001b[A\n",
            "Generating train examples...:  93% 46389/50000 [00:30<00:02, 1515.43 examples/s]\u001b[A\n",
            "Generating train examples...:  93% 46551/50000 [00:30<00:02, 1545.34 examples/s]\u001b[A\n",
            "Generating train examples...:  93% 46706/50000 [00:30<00:02, 1528.90 examples/s]\u001b[A\n",
            "Generating train examples...:  94% 46860/50000 [00:31<00:02, 1531.14 examples/s]\u001b[A\n",
            "Generating train examples...:  94% 47014/50000 [00:31<00:01, 1532.33 examples/s]\u001b[A\n",
            "Generating train examples...:  94% 47168/50000 [00:31<00:01, 1518.50 examples/s]\u001b[A\n",
            "Generating train examples...:  95% 47329/50000 [00:31<00:01, 1544.71 examples/s]\u001b[A\n",
            "Generating train examples...:  95% 47490/50000 [00:31<00:01, 1562.94 examples/s]\u001b[A\n",
            "Generating train examples...:  95% 47647/50000 [00:31<00:01, 1553.72 examples/s]\u001b[A\n",
            "Generating train examples...:  96% 47803/50000 [00:31<00:01, 1526.20 examples/s]\u001b[A\n",
            "Generating train examples...:  96% 47956/50000 [00:31<00:01, 1510.15 examples/s]\u001b[A\n",
            "Generating train examples...:  96% 48114/50000 [00:31<00:01, 1528.99 examples/s]\u001b[A\n",
            "Generating train examples...:  97% 48279/50000 [00:32<00:01, 1564.23 examples/s]\u001b[A\n",
            "Generating train examples...:  97% 48436/50000 [00:32<00:01, 1524.77 examples/s]\u001b[A\n",
            "Generating train examples...:  97% 48592/50000 [00:32<00:00, 1533.63 examples/s]\u001b[A\n",
            "Generating train examples...:  97% 48747/50000 [00:32<00:00, 1534.83 examples/s]\u001b[A\n",
            "Generating train examples...:  98% 48905/50000 [00:32<00:00, 1545.90 examples/s]\u001b[A\n",
            "Generating train examples...:  98% 49065/50000 [00:32<00:00, 1560.58 examples/s]\u001b[A\n",
            "Generating train examples...:  98% 49222/50000 [00:32<00:00, 1559.97 examples/s]\u001b[A\n",
            "Generating train examples...:  99% 49384/50000 [00:32<00:00, 1576.75 examples/s]\u001b[A\n",
            "Generating train examples...:  99% 49547/50000 [00:32<00:00, 1589.90 examples/s]\u001b[A\n",
            "Generating train examples...:  99% 49707/50000 [00:32<00:00, 1544.69 examples/s]\u001b[A\n",
            "Generating train examples...: 100% 49874/50000 [00:33<00:00, 1579.40 examples/s]\u001b[A\n",
            "                                                                                \u001b[A\n",
            "Shuffling cifar10-train.tfrecord...:   0% 0/50000 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling cifar10-train.tfrecord...:  13% 6700/50000 [00:00<00:00, 66992.40 examples/s]\u001b[A\n",
            "Shuffling cifar10-train.tfrecord...:  39% 19668/50000 [00:00<00:00, 103655.45 examples/s]\u001b[A\n",
            "Shuffling cifar10-train.tfrecord...:  69% 34389/50000 [00:00<00:00, 123514.17 examples/s]\u001b[A\n",
            "Shuffling cifar10-train.tfrecord...:  97% 48278/50000 [00:00<00:00, 129346.74 examples/s]\u001b[A\n",
            "                                                                                         \u001b[AI0808 19:27:49.056013 139645475628928 tfrecords_writer.py:328] Done writing cifar10-train.tfrecord. Number of examples: 50000 (shards: [50000])\n",
            "Generating splits...:  50% 1/2 [00:33<00:33, 33.58s/ splits]\n",
            "Generating test examples...:   0% 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
            "Generating test examples...:   1% 82/10000 [00:00<00:12, 818.63 examples/s]\u001b[A\n",
            "Generating test examples...:   2% 233/10000 [00:00<00:07, 1224.26 examples/s]\u001b[A\n",
            "Generating test examples...:   4% 383/10000 [00:00<00:07, 1349.85 examples/s]\u001b[A\n",
            "Generating test examples...:   5% 534/10000 [00:00<00:06, 1410.46 examples/s]\u001b[A\n",
            "Generating test examples...:   7% 697/10000 [00:00<00:06, 1486.62 examples/s]\u001b[A\n",
            "Generating test examples...:   9% 855/10000 [00:00<00:06, 1514.90 examples/s]\u001b[A\n",
            "Generating test examples...:  10% 1007/10000 [00:00<00:05, 1506.66 examples/s]\u001b[A\n",
            "Generating test examples...:  12% 1171/10000 [00:00<00:05, 1548.54 examples/s]\u001b[A\n",
            "Generating test examples...:  13% 1332/10000 [00:00<00:05, 1565.66 examples/s]\u001b[A\n",
            "Generating test examples...:  15% 1489/10000 [00:01<00:05, 1549.47 examples/s]\u001b[A\n",
            "Generating test examples...:  17% 1655/10000 [00:01<00:05, 1582.88 examples/s]\u001b[A\n",
            "Generating test examples...:  18% 1814/10000 [00:01<00:05, 1566.73 examples/s]\u001b[A\n",
            "Generating test examples...:  20% 1971/10000 [00:01<00:05, 1565.65 examples/s]\u001b[A\n",
            "Generating test examples...:  21% 2128/10000 [00:01<00:05, 1551.90 examples/s]\u001b[A\n",
            "Generating test examples...:  23% 2284/10000 [00:01<00:05, 1533.96 examples/s]\u001b[A\n",
            "Generating test examples...:  24% 2446/10000 [00:01<00:04, 1558.37 examples/s]\u001b[A\n",
            "Generating test examples...:  26% 2602/10000 [00:01<00:04, 1557.23 examples/s]\u001b[A\n",
            "Generating test examples...:  28% 2765/10000 [00:01<00:04, 1577.51 examples/s]\u001b[A\n",
            "Generating test examples...:  29% 2923/10000 [00:01<00:04, 1532.77 examples/s]\u001b[A\n",
            "Generating test examples...:  31% 3077/10000 [00:02<00:04, 1522.44 examples/s]\u001b[A\n",
            "Generating test examples...:  32% 3246/10000 [00:02<00:04, 1569.88 examples/s]\u001b[A\n",
            "Generating test examples...:  34% 3405/10000 [00:02<00:04, 1574.76 examples/s]\u001b[A\n",
            "Generating test examples...:  36% 3569/10000 [00:02<00:04, 1590.96 examples/s]\u001b[A\n",
            "Generating test examples...:  37% 3729/10000 [00:02<00:03, 1574.62 examples/s]\u001b[A\n",
            "Generating test examples...:  39% 3887/10000 [00:02<00:03, 1552.31 examples/s]\u001b[A\n",
            "Generating test examples...:  41% 4053/10000 [00:02<00:03, 1581.49 examples/s]\u001b[A\n",
            "Generating test examples...:  42% 4217/10000 [00:02<00:03, 1596.58 examples/s]\u001b[A\n",
            "Generating test examples...:  44% 4377/10000 [00:02<00:03, 1563.76 examples/s]\u001b[A\n",
            "Generating test examples...:  45% 4534/10000 [00:02<00:03, 1552.53 examples/s]\u001b[A\n",
            "Generating test examples...:  47% 4697/10000 [00:03<00:03, 1572.69 examples/s]\u001b[A\n",
            "Generating test examples...:  49% 4855/10000 [00:03<00:03, 1564.06 examples/s]\u001b[A\n",
            "Generating test examples...:  50% 5022/10000 [00:03<00:03, 1592.34 examples/s]\u001b[A\n",
            "Generating test examples...:  52% 5182/10000 [00:03<00:03, 1566.55 examples/s]\u001b[A\n",
            "Generating test examples...:  53% 5339/10000 [00:03<00:03, 1547.09 examples/s]\u001b[A\n",
            "Generating test examples...:  55% 5499/10000 [00:03<00:02, 1560.37 examples/s]\u001b[A\n",
            "Generating test examples...:  57% 5656/10000 [00:03<00:02, 1560.25 examples/s]\u001b[A\n",
            "Generating test examples...:  58% 5820/10000 [00:03<00:02, 1581.56 examples/s]\u001b[A\n",
            "Generating test examples...:  60% 5979/10000 [00:03<00:02, 1556.97 examples/s]\u001b[A\n",
            "Generating test examples...:  61% 6142/10000 [00:03<00:02, 1575.88 examples/s]\u001b[A\n",
            "Generating test examples...:  63% 6307/10000 [00:04<00:02, 1597.63 examples/s]\u001b[A\n",
            "Generating test examples...:  65% 6467/10000 [00:04<00:02, 1590.27 examples/s]\u001b[A\n",
            "Generating test examples...:  66% 6627/10000 [00:04<00:02, 1588.36 examples/s]\u001b[A\n",
            "Generating test examples...:  68% 6788/10000 [00:04<00:02, 1592.17 examples/s]\u001b[A\n",
            "Generating test examples...:  69% 6948/10000 [00:04<00:01, 1526.98 examples/s]\u001b[A\n",
            "Generating test examples...:  71% 7112/10000 [00:04<00:01, 1558.64 examples/s]\u001b[A\n",
            "Generating test examples...:  73% 7278/10000 [00:04<00:01, 1586.28 examples/s]\u001b[A\n",
            "Generating test examples...:  74% 7438/10000 [00:04<00:01, 1587.95 examples/s]\u001b[A\n",
            "Generating test examples...:  76% 7601/10000 [00:04<00:01, 1598.37 examples/s]\u001b[A\n",
            "Generating test examples...:  78% 7762/10000 [00:05<00:01, 1560.97 examples/s]\u001b[A\n",
            "Generating test examples...:  79% 7919/10000 [00:05<00:01, 1542.44 examples/s]\u001b[A\n",
            "Generating test examples...:  81% 8074/10000 [00:05<00:01, 1542.99 examples/s]\u001b[A\n",
            "Generating test examples...:  82% 8229/10000 [00:05<00:01, 1518.94 examples/s]\u001b[A\n",
            "Generating test examples...:  84% 8382/10000 [00:05<00:01, 1497.96 examples/s]\u001b[A\n",
            "Generating test examples...:  85% 8545/10000 [00:05<00:00, 1536.28 examples/s]\u001b[A\n",
            "Generating test examples...:  87% 8700/10000 [00:05<00:00, 1538.60 examples/s]\u001b[A\n",
            "Generating test examples...:  89% 8858/10000 [00:05<00:00, 1547.88 examples/s]\u001b[A\n",
            "Generating test examples...:  90% 9013/10000 [00:05<00:00, 1529.83 examples/s]\u001b[A\n",
            "Generating test examples...:  92% 9168/10000 [00:05<00:00, 1534.21 examples/s]\u001b[A\n",
            "Generating test examples...:  93% 9322/10000 [00:06<00:00, 1531.84 examples/s]\u001b[A\n",
            "Generating test examples...:  95% 9476/10000 [00:06<00:00, 1514.43 examples/s]\u001b[A\n",
            "Generating test examples...:  96% 9641/10000 [00:06<00:00, 1554.27 examples/s]\u001b[A\n",
            "Generating test examples...:  98% 9800/10000 [00:06<00:00, 1564.76 examples/s]\u001b[A\n",
            "Generating test examples...: 100% 9957/10000 [00:06<00:00, 1558.02 examples/s]\u001b[A\n",
            "                                                                              \u001b[A\n",
            "Shuffling cifar10-test.tfrecord...:   0% 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
            "                                                                        \u001b[AI0808 19:27:55.648282 139645475628928 tfrecords_writer.py:328] Done writing cifar10-test.tfrecord. Number of examples: 10000 (shards: [10000])\n",
            "\u001b[1mDataset cifar10 downloaded and prepared to /root/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:356: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_id has been renamed to jax.process_index. This alias \"\n",
            "/usr/local/lib/python3.7/dist-packages/jax/lib/xla_bridge.py:369: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_count has been renamed to jax.process_count. This alias \"\n",
            "I0808 19:27:55.665495 139645475628928 input_pipeline.py:171] Configure augmentation type randaugment\n",
            "I0808 19:27:55.665981 139645475628928 augment_utils.py:37] Using augmentation randaugment with parameters {'cutout': False, 'magnitude': 9, 'magstd': 0.5, 'num_layers': 2, 'prob_to_apply': 0.5, 'size': 32}\n",
            "I0808 19:27:55.666152 139645475628928 input_pipeline.py:192] Configure mix augmentation type mixup_alpha: 0.8\n",
            "prob_to_apply: 1.0\n",
            "smoothing: 0.1\n",
            "\n",
            "I0808 19:27:55.806274 139645475628928 logging_logger.py:34] Constructing tf.data.Dataset cifar10 for split ReadInstruction([_RelativeInstruction(splitname='train', from_=0, to=50000, unit='abs', rounding='closest')]), from /root/tensorflow_datasets/cifar10/3.0.2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "W0808 19:27:57.346666 139645475628928 deprecation.py:534] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0808 19:28:03.184146 139645475628928 deprecation.py:601] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0808 19:28:03.184614 139645475628928 deprecation.py:534] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I0808 19:28:03.304591 139645475628928 logging_logger.py:34] Constructing tf.data.Dataset cifar10 for split ReadInstruction([_RelativeInstruction(splitname='test', from_=0, to=10000, unit='abs', rounding='closest')]), from /root/tensorflow_datasets/cifar10/3.0.2\n",
            "I0808 19:28:05.131896 139645475628928 train.py:325] global_batch_size=192, num_train_steps=78125, steps_per_epoch=260, eval_every_steps=1300\n",
            "I0808 19:29:00.879901 139645475628928 parameter_overview.py:257] \n",
            "+---------------------------------------------------------------+------------------+---------+-----------+--------+\n",
            "| Name                                                          | Shape            | Size    | Mean      | Std    |\n",
            "+---------------------------------------------------------------+------------------+---------+-----------+--------+\n",
            "| ConvPool_0/Conv_0/bias                                        | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| ConvPool_0/Conv_0/kernel                                      | (3, 3, 192, 192) | 331,776 | 7.57e-05  | 0.0176 |\n",
            "| ConvPool_0/LayerNorm_0/bias                                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| ConvPool_0/LayerNorm_0/scale                                  | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| ConvPool_1/Conv_0/bias                                        | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| ConvPool_1/Conv_0/kernel                                      | (3, 3, 192, 192) | 331,776 | 6.01e-05  | 0.0176 |\n",
            "| ConvPool_1/LayerNorm_0/bias                                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| ConvPool_1/LayerNorm_0/scale                                  | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| ConvPool_2/Conv_0/bias                                        | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| ConvPool_2/Conv_0/kernel                                      | (3, 3, 192, 192) | 331,776 | -2.04e-05 | 0.0176 |\n",
            "| ConvPool_2/LayerNorm_0/bias                                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| ConvPool_2/LayerNorm_0/scale                                  | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| Dense_0/bias                                                  | (10,)            | 10      | 0.0       | 0.0    |\n",
            "| Dense_0/kernel                                                | (192, 10)        | 1,920   | 0.000134  | 0.0175 |\n",
            "| EncoderNDBlock_0/LayerNorm_0/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_0/LayerNorm_0/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_0/LayerNorm_1/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_0/LayerNorm_1/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_0/MlpBlock_0/Dense_0/bias                      | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_0/MlpBlock_0/Dense_0/kernel                    | (192, 768)       | 147,456 | -4.43e-05 | 0.0176 |\n",
            "| EncoderNDBlock_0/MlpBlock_0/Dense_1/bias                      | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_0/MlpBlock_0/Dense_1/kernel                    | (768, 192)       | 147,456 | -3.52e-05 | 0.0176 |\n",
            "| EncoderNDBlock_0/MultiQueryAttention_0/DenseGeneral_0/bias    | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_0/MultiQueryAttention_0/DenseGeneral_0/kernel  | (192, 3, 64)     | 36,864  | -2.46e-05 | 0.0177 |\n",
            "| EncoderNDBlock_0/MultiQueryAttention_0/Dense_0/bias           | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_0/MultiQueryAttention_0/Dense_0/kernel         | (192, 128)       | 24,576  | 3.25e-05  | 0.0176 |\n",
            "| EncoderNDBlock_0/MultiQueryAttention_0/bias                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_0/MultiQueryAttention_0/proj_kernel            | (3, 64, 192)     | 36,864  | -9.14e-05 | 0.0176 |\n",
            "| EncoderNDBlock_1/LayerNorm_0/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_1/LayerNorm_0/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_1/LayerNorm_1/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_1/LayerNorm_1/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_1/MlpBlock_0/Dense_0/bias                      | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_1/MlpBlock_0/Dense_0/kernel                    | (192, 768)       | 147,456 | -4.07e-05 | 0.0176 |\n",
            "| EncoderNDBlock_1/MlpBlock_0/Dense_1/bias                      | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_1/MlpBlock_0/Dense_1/kernel                    | (768, 192)       | 147,456 | -7.86e-05 | 0.0175 |\n",
            "| EncoderNDBlock_1/MultiQueryAttention_0/DenseGeneral_0/bias    | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_1/MultiQueryAttention_0/DenseGeneral_0/kernel  | (192, 3, 64)     | 36,864  | -6.74e-05 | 0.0177 |\n",
            "| EncoderNDBlock_1/MultiQueryAttention_0/Dense_0/bias           | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_1/MultiQueryAttention_0/Dense_0/kernel         | (192, 128)       | 24,576  | -0.000144 | 0.0177 |\n",
            "| EncoderNDBlock_1/MultiQueryAttention_0/bias                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_1/MultiQueryAttention_0/proj_kernel            | (3, 64, 192)     | 36,864  | -6.35e-05 | 0.0176 |\n",
            "| EncoderNDBlock_10/LayerNorm_0/bias                            | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_10/LayerNorm_0/scale                           | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_10/LayerNorm_1/bias                            | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_10/LayerNorm_1/scale                           | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_10/MlpBlock_0/Dense_0/bias                     | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_10/MlpBlock_0/Dense_0/kernel                   | (192, 768)       | 147,456 | 3.8e-05   | 0.0176 |\n",
            "| EncoderNDBlock_10/MlpBlock_0/Dense_1/bias                     | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_10/MlpBlock_0/Dense_1/kernel                   | (768, 192)       | 147,456 | 7.13e-05  | 0.0176 |\n",
            "| EncoderNDBlock_10/MultiQueryAttention_0/DenseGeneral_0/bias   | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_10/MultiQueryAttention_0/DenseGeneral_0/kernel | (192, 3, 64)     | 36,864  | -0.000119 | 0.0176 |\n",
            "| EncoderNDBlock_10/MultiQueryAttention_0/Dense_0/bias          | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_10/MultiQueryAttention_0/Dense_0/kernel        | (192, 128)       | 24,576  | -8.78e-05 | 0.0174 |\n",
            "| EncoderNDBlock_10/MultiQueryAttention_0/bias                  | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_10/MultiQueryAttention_0/proj_kernel           | (3, 64, 192)     | 36,864  | -0.000107 | 0.0176 |\n",
            "| EncoderNDBlock_11/LayerNorm_0/bias                            | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_11/LayerNorm_0/scale                           | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_11/LayerNorm_1/bias                            | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_11/LayerNorm_1/scale                           | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_11/MlpBlock_0/Dense_0/bias                     | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_11/MlpBlock_0/Dense_0/kernel                   | (192, 768)       | 147,456 | 1.7e-05   | 0.0176 |\n",
            "| EncoderNDBlock_11/MlpBlock_0/Dense_1/bias                     | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_11/MlpBlock_0/Dense_1/kernel                   | (768, 192)       | 147,456 | -1.92e-05 | 0.0176 |\n",
            "| EncoderNDBlock_11/MultiQueryAttention_0/DenseGeneral_0/bias   | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_11/MultiQueryAttention_0/DenseGeneral_0/kernel | (192, 3, 64)     | 36,864  | -4.01e-05 | 0.0176 |\n",
            "| EncoderNDBlock_11/MultiQueryAttention_0/Dense_0/bias          | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_11/MultiQueryAttention_0/Dense_0/kernel        | (192, 128)       | 24,576  | 0.000141  | 0.0176 |\n",
            "| EncoderNDBlock_11/MultiQueryAttention_0/bias                  | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_11/MultiQueryAttention_0/proj_kernel           | (3, 64, 192)     | 36,864  | 9.2e-05   | 0.0176 |\n",
            "| EncoderNDBlock_2/LayerNorm_0/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_2/LayerNorm_0/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_2/LayerNorm_1/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_2/LayerNorm_1/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_2/MlpBlock_0/Dense_0/bias                      | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_2/MlpBlock_0/Dense_0/kernel                    | (192, 768)       | 147,456 | -2.29e-05 | 0.0176 |\n",
            "| EncoderNDBlock_2/MlpBlock_0/Dense_1/bias                      | (192,)           | 192     | 0.0       | 0.0    |\n",
            "I0808 19:29:00.880270 139645475628928 parameter_overview.py:257] \n",
            "| EncoderNDBlock_2/MlpBlock_0/Dense_1/kernel                    | (768, 192)       | 147,456 | 4.43e-05  | 0.0176 |\n",
            "| EncoderNDBlock_2/MultiQueryAttention_0/DenseGeneral_0/bias    | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_2/MultiQueryAttention_0/DenseGeneral_0/kernel  | (192, 3, 64)     | 36,864  | -8.5e-05  | 0.0175 |\n",
            "| EncoderNDBlock_2/MultiQueryAttention_0/Dense_0/bias           | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_2/MultiQueryAttention_0/Dense_0/kernel         | (192, 128)       | 24,576  | -3.93e-05 | 0.0177 |\n",
            "| EncoderNDBlock_2/MultiQueryAttention_0/bias                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_2/MultiQueryAttention_0/proj_kernel            | (3, 64, 192)     | 36,864  | 5.65e-05  | 0.0176 |\n",
            "| EncoderNDBlock_3/LayerNorm_0/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_3/LayerNorm_0/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_3/LayerNorm_1/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_3/LayerNorm_1/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_3/MlpBlock_0/Dense_0/bias                      | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_3/MlpBlock_0/Dense_0/kernel                    | (192, 768)       | 147,456 | -4.91e-05 | 0.0176 |\n",
            "| EncoderNDBlock_3/MlpBlock_0/Dense_1/bias                      | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_3/MlpBlock_0/Dense_1/kernel                    | (768, 192)       | 147,456 | -9.79e-06 | 0.0175 |\n",
            "| EncoderNDBlock_3/MultiQueryAttention_0/DenseGeneral_0/bias    | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_3/MultiQueryAttention_0/DenseGeneral_0/kernel  | (192, 3, 64)     | 36,864  | -2.98e-05 | 0.0175 |\n",
            "| EncoderNDBlock_3/MultiQueryAttention_0/Dense_0/bias           | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_3/MultiQueryAttention_0/Dense_0/kernel         | (192, 128)       | 24,576  | -9.08e-05 | 0.0175 |\n",
            "| EncoderNDBlock_3/MultiQueryAttention_0/bias                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_3/MultiQueryAttention_0/proj_kernel            | (3, 64, 192)     | 36,864  | 0.000311  | 0.0176 |\n",
            "| EncoderNDBlock_4/LayerNorm_0/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_4/LayerNorm_0/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_4/LayerNorm_1/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_4/LayerNorm_1/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_4/MlpBlock_0/Dense_0/bias                      | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_4/MlpBlock_0/Dense_0/kernel                    | (192, 768)       | 147,456 | -3.3e-05  | 0.0176 |\n",
            "| EncoderNDBlock_4/MlpBlock_0/Dense_1/bias                      | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_4/MlpBlock_0/Dense_1/kernel                    | (768, 192)       | 147,456 | 9.76e-06  | 0.0176 |\n",
            "| EncoderNDBlock_4/MultiQueryAttention_0/DenseGeneral_0/bias    | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_4/MultiQueryAttention_0/DenseGeneral_0/kernel  | (192, 3, 64)     | 36,864  | 1.41e-05  | 0.0177 |\n",
            "| EncoderNDBlock_4/MultiQueryAttention_0/Dense_0/bias           | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_4/MultiQueryAttention_0/Dense_0/kernel         | (192, 128)       | 24,576  | 4.78e-05  | 0.0175 |\n",
            "| EncoderNDBlock_4/MultiQueryAttention_0/bias                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_4/MultiQueryAttention_0/proj_kernel            | (3, 64, 192)     | 36,864  | 0.000271  | 0.0176 |\n",
            "| EncoderNDBlock_5/LayerNorm_0/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_5/LayerNorm_0/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_5/LayerNorm_1/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_5/LayerNorm_1/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_5/MlpBlock_0/Dense_0/bias                      | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_5/MlpBlock_0/Dense_0/kernel                    | (192, 768)       | 147,456 | -3.26e-05 | 0.0176 |\n",
            "| EncoderNDBlock_5/MlpBlock_0/Dense_1/bias                      | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_5/MlpBlock_0/Dense_1/kernel                    | (768, 192)       | 147,456 | -2.65e-05 | 0.0176 |\n",
            "| EncoderNDBlock_5/MultiQueryAttention_0/DenseGeneral_0/bias    | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_5/MultiQueryAttention_0/DenseGeneral_0/kernel  | (192, 3, 64)     | 36,864  | -0.000181 | 0.0176 |\n",
            "| EncoderNDBlock_5/MultiQueryAttention_0/Dense_0/bias           | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_5/MultiQueryAttention_0/Dense_0/kernel         | (192, 128)       | 24,576  | -0.00013  | 0.0177 |\n",
            "| EncoderNDBlock_5/MultiQueryAttention_0/bias                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_5/MultiQueryAttention_0/proj_kernel            | (3, 64, 192)     | 36,864  | -4.3e-05  | 0.0176 |\n",
            "| EncoderNDBlock_6/LayerNorm_0/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_6/LayerNorm_0/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_6/LayerNorm_1/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_6/LayerNorm_1/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_6/MlpBlock_0/Dense_0/bias                      | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_6/MlpBlock_0/Dense_0/kernel                    | (192, 768)       | 147,456 | -6.04e-05 | 0.0176 |\n",
            "| EncoderNDBlock_6/MlpBlock_0/Dense_1/bias                      | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_6/MlpBlock_0/Dense_1/kernel                    | (768, 192)       | 147,456 | 5.92e-05  | 0.0176 |\n",
            "| EncoderNDBlock_6/MultiQueryAttention_0/DenseGeneral_0/bias    | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_6/MultiQueryAttention_0/DenseGeneral_0/kernel  | (192, 3, 64)     | 36,864  | -0.000144 | 0.0176 |\n",
            "| EncoderNDBlock_6/MultiQueryAttention_0/Dense_0/bias           | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_6/MultiQueryAttention_0/Dense_0/kernel         | (192, 128)       | 24,576  | -0.000105 | 0.0176 |\n",
            "| EncoderNDBlock_6/MultiQueryAttention_0/bias                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_6/MultiQueryAttention_0/proj_kernel            | (3, 64, 192)     | 36,864  | -1.24e-05 | 0.0176 |\n",
            "| EncoderNDBlock_7/LayerNorm_0/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_7/LayerNorm_0/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_7/LayerNorm_1/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_7/LayerNorm_1/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_7/MlpBlock_0/Dense_0/bias                      | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_7/MlpBlock_0/Dense_0/kernel                    | (192, 768)       | 147,456 | 2.83e-05  | 0.0176 |\n",
            "| EncoderNDBlock_7/MlpBlock_0/Dense_1/bias                      | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_7/MlpBlock_0/Dense_1/kernel                    | (768, 192)       | 147,456 | 6.3e-05   | 0.0176 |\n",
            "| EncoderNDBlock_7/MultiQueryAttention_0/DenseGeneral_0/bias    | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_7/MultiQueryAttention_0/DenseGeneral_0/kernel  | (192, 3, 64)     | 36,864  | -5.2e-05  | 0.0176 |\n",
            "| EncoderNDBlock_7/MultiQueryAttention_0/Dense_0/bias           | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_7/MultiQueryAttention_0/Dense_0/kernel         | (192, 128)       | 24,576  | 0.000103  | 0.0176 |\n",
            "| EncoderNDBlock_7/MultiQueryAttention_0/bias                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_7/MultiQueryAttention_0/proj_kernel            | (3, 64, 192)     | 36,864  | -8.39e-05 | 0.0176 |\n",
            "| EncoderNDBlock_8/LayerNorm_0/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_8/LayerNorm_0/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_8/LayerNorm_1/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "I0808 19:29:00.953182 139645475628928 parameter_overview.py:257] \n",
            "| EncoderNDBlock_8/LayerNorm_1/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_8/MlpBlock_0/Dense_0/bias                      | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_8/MlpBlock_0/Dense_0/kernel                    | (192, 768)       | 147,456 | 7.48e-06  | 0.0176 |\n",
            "| EncoderNDBlock_8/MlpBlock_0/Dense_1/bias                      | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_8/MlpBlock_0/Dense_1/kernel                    | (768, 192)       | 147,456 | -2.77e-05 | 0.0175 |\n",
            "| EncoderNDBlock_8/MultiQueryAttention_0/DenseGeneral_0/bias    | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_8/MultiQueryAttention_0/DenseGeneral_0/kernel  | (192, 3, 64)     | 36,864  | -4.55e-05 | 0.0176 |\n",
            "| EncoderNDBlock_8/MultiQueryAttention_0/Dense_0/bias           | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_8/MultiQueryAttention_0/Dense_0/kernel         | (192, 128)       | 24,576  | 8.08e-06  | 0.0176 |\n",
            "| EncoderNDBlock_8/MultiQueryAttention_0/bias                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_8/MultiQueryAttention_0/proj_kernel            | (3, 64, 192)     | 36,864  | 6.56e-05  | 0.0176 |\n",
            "| EncoderNDBlock_9/LayerNorm_0/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_9/LayerNorm_0/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_9/LayerNorm_1/bias                             | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_9/LayerNorm_1/scale                            | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| EncoderNDBlock_9/MlpBlock_0/Dense_0/bias                      | (768,)           | 768     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_9/MlpBlock_0/Dense_0/kernel                    | (192, 768)       | 147,456 | -3.15e-05 | 0.0177 |\n",
            "| EncoderNDBlock_9/MlpBlock_0/Dense_1/bias                      | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_9/MlpBlock_0/Dense_1/kernel                    | (768, 192)       | 147,456 | -5.74e-05 | 0.0176 |\n",
            "| EncoderNDBlock_9/MultiQueryAttention_0/DenseGeneral_0/bias    | (3, 64)          | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_9/MultiQueryAttention_0/DenseGeneral_0/kernel  | (192, 3, 64)     | 36,864  | -1.03e-05 | 0.0176 |\n",
            "| EncoderNDBlock_9/MultiQueryAttention_0/Dense_0/bias           | (128,)           | 128     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_9/MultiQueryAttention_0/Dense_0/kernel         | (192, 128)       | 24,576  | 4.03e-05  | 0.0176 |\n",
            "| EncoderNDBlock_9/MultiQueryAttention_0/bias                   | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| EncoderNDBlock_9/MultiQueryAttention_0/proj_kernel            | (3, 64, 192)     | 36,864  | 2.45e-05  | 0.0176 |\n",
            "| LayerNorm_0/bias                                              | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| LayerNorm_0/scale                                             | (192,)           | 192     | 1.0       | 0.0    |\n",
            "| PatchEmbedding_0/Conv_0/bias                                  | (192,)           | 192     | 0.0       | 0.0    |\n",
            "| PatchEmbedding_0/Conv_0/kernel                                | (1, 1, 3, 192)   | 576     | -0.000802 | 0.0178 |\n",
            "| PositionEmbedding_0/pos_embedding                             | (1, 64, 16, 192) | 196,608 | 9.2e-06   | 0.0176 |\n",
            "| PositionEmbedding_1/pos_embedding                             | (1, 16, 16, 192) | 49,152  | -1.1e-05  | 0.0176 |\n",
            "| PositionEmbedding_2/pos_embedding                             | (1, 4, 16, 192)  | 12,288  | -0.000185 | 0.0175 |\n",
            "| PositionEmbedding_3/pos_embedding                             | (1, 1, 16, 192)  | 3,072   | 0.000262  | 0.0179 |\n",
            "+---------------------------------------------------------------+------------------+---------+-----------+--------+\n",
            "Total: 6,006,730\n",
            "I0808 19:29:01.680581 139645475628928 utils.py:31] Checkpoint.restore_or_initialize() ...\n",
            "I0808 19:29:01.680755 139645475628928 checkpoint.py:301] No checkpoint specified. Restore the latest checkpoint.\n",
            "I0808 19:29:01.680824 139645475628928 utils.py:31] MultihostCheckpoint.get_latest_checkpoint_to_restore_from() ...\n",
            "I0808 19:29:01.681328 139645475628928 utils.py:41] MultihostCheckpoint.get_latest_checkpoint_to_restore_from() finished after 0.00s.\n",
            "I0808 19:29:01.681468 139645475628928 checkpoint.py:304] Checkpoint None does not exist.\n",
            "I0808 19:29:01.681542 139645475628928 utils.py:31] Checkpoint.save() ...\n",
            "I0808 19:29:01.996730 139645475628928 utils.py:41] Checkpoint.save() finished after 0.32s.\n",
            "I0808 19:29:01.997014 139645475628928 utils.py:41] Checkpoint.restore_or_initialize() finished after 0.32s.\n",
            "I0808 19:29:02.120529 139642811893504 logging_writer.py:56] Hyperparameters: {'augment': randaugment_cutout: false\n",
            "randaugment_magnitude: 9\n",
            "randaugment_magstd: 0.5\n",
            "randaugment_num_layers: 2\n",
            "randaugment_prob_to_apply: 0.5\n",
            "size: 32\n",
            "type: randaugment\n",
            ", 'checkpoint_every_steps': 5000, 'dataset': 'cifar10', 'eval_every_steps': -1, 'eval_pad_last_batch': True, 'eval_per_epochs': 5, 'grad_clip_max_norm': 0, 'learning_rate': 0.00025, 'learning_rate_schedule': 'cosine', 'log_loss_every_steps': 500, 'mix': mixup_alpha: 0.8\n",
            "prob_to_apply: 1.0\n",
            "smoothing: 0.1\n",
            ", 'model_name': 'nest_tiny_s16_32', 'num_epochs': 300, 'num_eval_steps': -1, 'num_train_steps': -1, 'optim': 'adamw', 'optim_wd_ignore': ['pos_embedding'], 'per_device_batch_size': 192, 'randerasing': erase_prob: 0.25\n",
            ", 'seed': 42, 'shuffle_buffer_size': 10000, 'trial': 0, 'warmup_epochs': 5, 'weight_decay': 0.05}\n",
            "I0808 19:29:02.123986 139645475628928 train.py:387] Starting training loop at step 1.\n",
            "I0808 19:29:04.062690 139645475628928 train.py:158] train_step(batch={'image': Traced<ShapedArray(float32[192,32,32,3])>with<DynamicJaxprTrace(level=0/1)>, 'label': Traced<ShapedArray(float32[192,10])>with<DynamicJaxprTrace(level=0/1)>})\n",
            "I0808 19:29:04.072015 139645475628928 utils.py:114] get_learning_rate(step=Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=0/1)>, base_learning_rate=0.0001875, steps_per_epoch=260, num_epochs=300\n",
            "2022-08-08 19:31:33.493892: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:55] \n",
            "********************************\n",
            "Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
            "Compiling module pmap__unnamed_wrapped_function_.58875\n",
            "********************************\n",
            "tcmalloc: large alloc 12897501184 bytes == 0x1dda10000 @  0x7f01beb34b6b 0x7f01beb54379 0x7f01badb4ea7 0x7f01bad6785b 0x7f01bad78a16 0x7f01bad7994d 0x7f01b6be33b9 0x7f01b6be6a50 0x7f01baa94472 0x7f01b818fad0 0x7f01b81901c0 0x7f01b816b745 0x7f01b8171f36 0x7f01b8173ce4 0x7f01b5d733cd 0x7f01b5ae3bd9 0x7f01b5ad25e1 0x593784 0x594731 0x548cc1 0x51566f 0x549576 0x4bcb19 0x5fbe79 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x5134a6 0x593dd7 0x511e2c\n",
            "I0808 19:32:54.026971 139645475628928 train.py:413] Finished training step 1.\n",
            "tcmalloc: large alloc 12897501184 bytes == 0x4ec556000 @  0x7f01beb34b6b 0x7f01beb54379 0x7f01badb4ea7 0x7f01bad6785b 0x7f01bad78a16 0x7f01bad7994d 0x7f01b6be33b9 0x7f01b6be6a50 0x7f01baa94472 0x7f01b818fad0 0x7f01b81901c0 0x7f01b816b745 0x7f01b8171f36 0x7f01b8173ce4 0x7f01b5d733cd 0x7f01b5ae3bd9 0x7f01b5ad25e1 0x593784 0x594731 0x548cc1 0x51566f 0x549576 0x4bcb19 0x5fbe79 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x5134a6 0x593dd7 0x511e2c\n",
            "I0808 19:32:54.592664 139645475628928 train.py:413] Finished training step 2.\n",
            "tcmalloc: large alloc 12897501184 bytes == 0x7ee15a000 @  0x7f01beb34b6b 0x7f01beb54379 0x7f01badb4ea7 0x7f01bad6785b 0x7f01bad78a16 0x7f01bad7994d 0x7f01b6be33b9 0x7f01b6be6a50 0x7f01baa94472 0x7f01b818fad0 0x7f01b81901c0 0x7f01b816b745 0x7f01b8171f36 0x7f01b8173ce4 0x7f01b5d733cd 0x7f01b5ae3bd9 0x7f01b5ad25e1 0x593784 0x594731 0x548cc1 0x51566f 0x549576 0x4bcb19 0x5fbe79 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x5134a6 0x593dd7 0x511e2c\n",
            "I0808 19:32:54.844292 139645475628928 train.py:413] Finished training step 3.\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python ./dipexercises/project/main.py --config dipexercises/project/configs/cifar_nest.py --workdir=\"./dipexercises/project/checkpoints/nest_cifar\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG5MZnIr6li1"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
