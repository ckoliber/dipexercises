{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIP Answers\n",
    "\n",
    "- **Answer Set**: Final Project\n",
    "- **Full Name**: Mohammad Hosein Nemati\n",
    "- **Student Code**: `610300185`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595aa20",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this problem, we are going to change some parameters in order to optimize the accuracy of [**Nested Hierarchical Transformer**](https://github.com/google-research/nested-transformer) model for **CIFAR10** dataset.  \n",
    "Then we will compare the reported metrics to previously trained models in `article`\n",
    "\n",
    "In the first step, we will install required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install absl-py\n",
    "!pip install clu==0.0.3\n",
    "!pip install flax==0.3.4\n",
    "!pip install jax==0.2.14\n",
    "!pip install jaxlib==0.1.67\n",
    "!pip install ml_collections\n",
    "!pip install tensorflow-cpu==2.5.0\n",
    "!pip install tensorflow-datasets==4.3.0\n",
    "!pip install tensorflow_addons==0.13.0\n",
    "\n",
    "!git clone https://github.com/ckoliber/dipexercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595aa20",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "In this section, we will change some parameters of model in order to optimize the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class NestNet(nn.Module):\n",
    "  \"\"\"Nested Transformer Net.\"\"\"\n",
    "  num_classes: int\n",
    "  config: ml_collections.ConfigDict\n",
    "  train: bool = False\n",
    "  dtype: int = jnp.float32\n",
    "  activation_fn: Any = nn.gelu\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs):\n",
    "    config = self.config\n",
    "    num_layers_per_block = config.num_layers_per_block\n",
    "    num_blocks = len(num_layers_per_block)\n",
    "    # Here we just assume image/patch size are squared.\n",
    "    assert inputs.shape[1] == inputs.shape[2]\n",
    "    assert inputs.shape[1] % config.init_patch_embed_size == 0\n",
    "    input_size_after_patch = inputs.shape[1] // config.init_patch_embed_size\n",
    "    assert input_size_after_patch % config.patch_size == 0\n",
    "    down_sample_ratio = input_size_after_patch // config.patch_size\n",
    "    # There are 4 child nodes for each node.\n",
    "    assert num_blocks == int(np.log(down_sample_ratio) / np.log(2) + 1)\n",
    "\n",
    "    # If `scale_hidden_dims` is provided, at every block, it increases hidden\n",
    "    # dimension and num_heads by `scale_hidden_dims`. Set `scale_hidden_dims=2`\n",
    "    # overall is a common design, so we do not gives the flexibility to control\n",
    "    # layer-wise `scale_hidden_dims` to simplify the architecture.\n",
    "    scale_hidden_dims = config.get(\"scale_hidden_dims\", None)\n",
    "\n",
    "    norm_fn = attn_utils.get_norm_layer(\n",
    "        self.train, self.dtype, norm_type=config.norm_type)\n",
    "    conv_fn = functools.partial(\n",
    "        nn.Conv, dtype=self.dtype, kernel_init=default_kernel_init)\n",
    "    dense_fn = functools.partial(\n",
    "        nn.Dense, dtype=self.dtype, kernel_init=default_kernel_init)\n",
    "    encoder_dict = dict(\n",
    "        num_heads=config.num_heads,\n",
    "        norm_fn=norm_fn,\n",
    "        mlp_ratio=config.mlp_ratio,\n",
    "        attn_type=config.attn_type,\n",
    "        dense_fn=dense_fn,\n",
    "        activation_fn=self.activation_fn,\n",
    "        qkv_bias=config.qkv_bias,\n",
    "        attn_drop=config.attn_drop,\n",
    "        proj_drop=config.proj_drop,\n",
    "        train=self.train,\n",
    "        dtype=self.dtype)\n",
    "    x = self_attention.PatchEmbedding(\n",
    "        conv_fn=conv_fn,\n",
    "        patch_size=(config.init_patch_embed_size, config.init_patch_embed_size),\n",
    "        embedding_dim=config.embedding_dim)(\n",
    "            inputs)\n",
    "    x = attn_utils.block_images(x, (config.patch_size, config.patch_size))\n",
    "    block_idx = 0\n",
    "    total_block_num = np.sum(num_layers_per_block)\n",
    "    path_drop = np.linspace(0, config.stochastic_depth_drop, total_block_num)\n",
    "    for i in range(num_blocks):\n",
    "      x = self_attention.PositionEmbedding()(x)\n",
    "      if scale_hidden_dims and i != 0:\n",
    "        # Overwrite the original num_heads value in encoder_dict so num_heads\n",
    "        # multipled by scale_hidden_dims continueously.\n",
    "        encoder_dict.update(\n",
    "            {\"num_heads\": encoder_dict[\"num_heads\"] * scale_hidden_dims})\n",
    "      for _ in range(num_layers_per_block[i]):\n",
    "        x = self_attention.EncoderNDBlock(\n",
    "            **encoder_dict, path_drop=path_drop[block_idx])(\n",
    "                x)\n",
    "        block_idx = block_idx + 1\n",
    "      if i < num_blocks - 1:\n",
    "        grid_size = int(math.sqrt(x.shape[1]))\n",
    "        if scale_hidden_dims:\n",
    "          output_dim = x.shape[-1] * scale_hidden_dims\n",
    "        else:\n",
    "          output_dim = None\n",
    "\n",
    "        x = self_attention.ConvPool(\n",
    "            grid_size=(grid_size, grid_size),\n",
    "            patch_size=(config.patch_size, config.patch_size),\n",
    "            conv_fn=conv_fn,\n",
    "            dtype=self.dtype,\n",
    "            output_dim=output_dim)(\n",
    "                x)\n",
    "    assert x.shape[1] == 1\n",
    "    assert x.shape[2] == config.patch_size**2\n",
    "\n",
    "    x = norm_fn()(x)\n",
    "    x_pool = jnp.mean(x, axis=(1, 2))\n",
    "    out = dense_fn(self.num_classes)(x_pool)\n",
    "    return out\n",
    "\n",
    "\n",
    "MODELS = {}\n",
    "\n",
    "\n",
    "def register(f):\n",
    "  MODELS[f.__name__] = f\n",
    "  return f\n",
    "\n",
    "\n",
    "def default_config():\n",
    "  \"\"\"Shared configs for models.\"\"\"\n",
    "  nest = ml_collections.ConfigDict()\n",
    "  nest.norm_type = \"LN\"\n",
    "  nest.attn_type = \"local_multi_head\"\n",
    "  nest.mlp_ratio = 4\n",
    "  nest.qkv_bias = True\n",
    "  nest.attn_drop = 0.0\n",
    "  nest.proj_drop = 0.0\n",
    "  nest.stochastic_depth_drop = 0.1\n",
    "  return nest\n",
    "\n",
    "\n",
    "@register\n",
    "def nest_tiny_s16_32(config):\n",
    "  \"\"\"NesT tiny version with sequence length 16 for 32x32 inputs.\"\"\"\n",
    "  nest = default_config()\n",
    "  # Encode one pixel as a word vector.\n",
    "  nest.init_patch_embed_size = 1\n",
    "  # Default max sequencee length is 4x4=16, so it has 4 layers.\n",
    "  nest.patch_size = 4\n",
    "  nest.num_layers_per_block = [3, 3, 3, 3]\n",
    "  nest.embedding_dim = 192\n",
    "  nest.num_heads = 3\n",
    "  nest.attn_type = \"local_multi_query\"\n",
    "\n",
    "  if config.get(\"nest\"):\n",
    "    nest.update(config.nest)\n",
    "  return functools.partial(NestNet, config=nest)\n",
    "\n",
    "\n",
    "@register\n",
    "def nest_small_s16_32(config):\n",
    "  \"\"\"NesT small version with sequence length 16 for 32x32 inputs.\"\"\"\n",
    "  nest = default_config()\n",
    "  nest.init_patch_embed_size = 1\n",
    "  nest.patch_size = 4\n",
    "  nest.num_layers_per_block = [3, 3, 3, 3]\n",
    "  nest.embedding_dim = 384\n",
    "  nest.num_heads = 6\n",
    "  nest.attn_type = \"local_multi_query\"\n",
    "\n",
    "  if config.get(\"nest\"):\n",
    "    nest.update(config.nest)\n",
    "  return functools.partial(NestNet, config=nest)\n",
    "\n",
    "\n",
    "@register\n",
    "def nest_base_s16_32(config):\n",
    "  \"\"\"NesT base version with sequence length 16 for 32x32 inputs.\"\"\"\n",
    "  nest = default_config()\n",
    "  nest.init_patch_embed_size = 1\n",
    "  nest.patch_size = 4\n",
    "  nest.num_layers_per_block = [3, 3, 3, 3]\n",
    "  nest.embedding_dim = 768\n",
    "  nest.num_heads = 12\n",
    "  nest.attn_type = \"local_multi_query\"\n",
    "\n",
    "  if config.get(\"nest\"):\n",
    "    nest.update(config.nest)\n",
    "  return functools.partial(NestNet, config=nest)\n",
    "\n",
    "\n",
    "@register\n",
    "def nest_tiny_s196_224(config):\n",
    "  \"\"\"NesT tiny version with sequence length 49 for 224x224 inputs.\"\"\"\n",
    "  nest = default_config()\n",
    "  # Encode 4x4 pixel as a word vector.\n",
    "  nest.init_patch_embed_size = 4\n",
    "  # Default max sequencee length is 14x14=196, so it has 3 layers:\n",
    "  # Spatial image size: [56, 28, 14]\n",
    "  nest.patch_size = 14\n",
    "  nest.num_layers_per_block = [2, 2, 8]\n",
    "  nest.embedding_dim = 96\n",
    "  nest.num_heads = 3\n",
    "  nest.scale_hidden_dims = 2\n",
    "  nest.stochastic_depth_drop = 0.2\n",
    "  nest.attn_type = \"local_multi_head\"\n",
    "\n",
    "  if config.get(\"nest\"):\n",
    "    nest.update(config.nest)\n",
    "  return functools.partial(NestNet, config=nest)\n",
    "\n",
    "\n",
    "@register\n",
    "def nest_small_s196_224(config):\n",
    "  \"\"\"NesT small version with sequence length 196 for 224x224 inputs.\"\"\"\n",
    "  nest = default_config()\n",
    "  nest.init_patch_embed_size = 4\n",
    "  nest.patch_size = 14\n",
    "  nest.num_layers_per_block = [2, 2, 20]\n",
    "  nest.embedding_dim = 96\n",
    "  nest.num_heads = 3\n",
    "  nest.scale_hidden_dims = 2\n",
    "  nest.stochastic_depth_drop = 0.3\n",
    "  nest.attn_type = \"local_multi_head\"\n",
    "\n",
    "  if config.get(\"nest\"):\n",
    "    nest.update(config.nest)\n",
    "  return functools.partial(NestNet, config=nest)\n",
    "\n",
    "\n",
    "@register\n",
    "def nest_base_s196_224(config):\n",
    "  \"\"\"NesT base version with sequence length 196 for 224x224 inputs.\"\"\"\n",
    "  nest = default_config()\n",
    "  nest.init_patch_embed_size = 4\n",
    "  nest.patch_size = 14\n",
    "  nest.num_layers_per_block = [2, 2, 20]\n",
    "  nest.embedding_dim = 128\n",
    "  nest.num_heads = 4\n",
    "  nest.scale_hidden_dims = 2\n",
    "  nest.stochastic_depth_drop = 0.5\n",
    "  nest.attn_type = \"local_multi_head\"\n",
    "\n",
    "  if config.get(\"nest\"):\n",
    "    nest.update(config.nest)\n",
    "  return functools.partial(NestNet, config=nest)\n",
    "\n",
    "\n",
    "def create_model(name, config):\n",
    "  \"\"\"Creates model partial function.\"\"\"\n",
    "  if name not in MODELS:\n",
    "    raise ValueError(f\"Model {name} does not exist.\")\n",
    "  return MODELS[name](config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Run the command bellow in order to train the `NesT` model and report evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python ./dipexercises/project/main.py --config dipexercises/project/configs/cifar_nest.py --workdir=\"./dipexercises/project/checkpoints/nest_cifar\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595aa20",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
